{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BibTexDatabase <817 entries>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    input = raw_input\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import pybib\n",
    "from pybib import BibTexParser\n",
    "from pybib.customization import BibEntry\n",
    "\n",
    "bp = BibTexParser(ignore_nonstandard_types=False, customization=BibEntry.from_file, common_strings=True)\n",
    "db = bp.parse_file(\"todo.bib\")\n",
    "assert len(db.entries) == sum(map(len, db.entries.duplicates.values())) + len(db.entries.index)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge(items):\n",
    "    out = {}\n",
    "    bad = {}\n",
    "    for i, item in enumerate(items):\n",
    "        for k,v in item.items():\n",
    "            if k in out:\n",
    "                if v!=out[k]:\n",
    "                    bad.setdefault(k, []).append(i)\n",
    "            else:\n",
    "                out[k] = v\n",
    "    return BibEntry(out), bad\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dups = db.entries.duplicates\n",
    "fixes = {}\n",
    "for entry_id, entry_items in dups.items():\n",
    "    fixes[entry_id] = merge(entry_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "+ Entry: jager:ac09\n",
      "\t At Issue Key: pages\n",
      "\t<0>- Accepted: 11-20\n",
      "\t<1>- Duplicate 2: 11-20\n",
      "\t<2>- Duplicate 3: 11-20\n",
      "Which to keep <0-2>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: Matuszek2012\n",
      "\t At Issue Key: author\n",
      "\t<0>- Accepted: Matuszek, Cynthia and Fitzgerald, Nicholas and Zettlemoyer, Luke and Bo, Liefeng and Fox, Dieter\n",
      "\t<1>- Duplicate 2: Matuszek, Cynthia and FitzGerald, N and Zettlemoyer, Luke\n",
      "\t<2>- Duplicate 3: Matuszek, Cynthia and FitzGerald, N and Zettlemoyer, Luke\n",
      "Which to keep <0-2>?: 0\n",
      "\t At Issue Key: ENTRYTYPE\n",
      "\t<0>- Accepted: inproceedings\n",
      "\t<1>- Duplicate 2: article\n",
      "\t<2>- Duplicate 3: article\n",
      "Which to keep <0-2>?: 0\n",
      "\t At Issue Key: title\n",
      "\t<0>- Accepted: A Joint Model of Language and Perception for Grounded Attribute Learning\n",
      "\t<1>- Duplicate 2: {A joint model of language and perception for grounded attribute learning}\n",
      "\t<2>- Duplicate 3: {A joint model of language and perception for grounded attribute learning}\n",
      "Which to keep <0-2>?: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: anderson1991adaptive\n",
      "\t At Issue Key: author\n",
      "\t<0>- Accepted: Anderson, John R.\n",
      "\t<1>- Duplicate 1: Anderson, John R\n",
      "Which to keep <0-1>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: kyburg/morreau:lp00\n",
      "\t At Issue Key: pages\n",
      "\t<0>- Accepted: 577--597\n",
      "\t<1>- Duplicate 2: 577-597\n",
      "\t<2>- Duplicate 3: 577-597\n",
      "Which to keep <0-2>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: simon1956rational\n",
      "\t At Issue Key: author\n",
      "\t<0>- Accepted: Simon, Herbert A.\n",
      "\t<1>- Duplicate 1: Simon, Herbert A\n",
      "\t<2>- Duplicate 2: Simon, Herbert A\n",
      "Which to keep <0-2>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: Tellex2011a\n",
      "\t At Issue Key: annote\n",
      "\t<0>- Accepted: Tellex factors the sentence into  a single structure and then assumes each constituent of that structure has a fixed grounding (path and object) and that each of these things is independent.\n",
      "This works well for descriptions describing actions that necessarily involve the environment.\n",
      "Does this have any downsides for general grounded semantics?  How should this fit into the larger picture? \n",
      "\t<1>- Duplicate 2: Tellex factors the sentence into  a single structure and then assumes each constituent of that structure has a fixed grounding (path and object) and that each of these things is independent.\n",
      "\n",
      "\n",
      "This works well for descriptions describing actions that necessarily involve the environment.\n",
      "\n",
      "\n",
      "Does this have any downsides for general grounded semantics?  How should this fit into the larger picture? \n",
      "\t<2>- Duplicate 3: Tellex factors the sentence into  a single structure and then assumes each constituent of that structure has a fixed grounding (path and object) and that each of these things is independent.\n",
      "\n",
      "\n",
      "This works well for descriptions describing actions that necessarily involve the environment.\n",
      "\n",
      "\n",
      "Does this have any downsides for general grounded semantics?  How should this fit into the larger picture? \n",
      "Which to keep <0-2>?: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: Tellex2011\n",
      "\t At Issue Key: author\n",
      "\t<0>- Accepted: Tellex, Stefanie and Kollar, Thomas and Dickerson, Steven and Walter, Matthew R and Banerjee, Ashis Gopal and Teller, Seth J and Roy, Nicholas\n",
      "\t<1>- Duplicate 2: Tellex, Stefanie and Kollar, Thomas and Dickerson, Steven\n",
      "\t<2>- Duplicate 3: Tellex, Stefanie and Kollar, Thomas and Dickerson, Steven\n",
      "Which to keep <0-2>?: 0\n",
      "\t At Issue Key: title\n",
      "\t<0>- Accepted: Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation.\n",
      "\t<1>- Duplicate 2: {Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation.}\n",
      "\t<2>- Duplicate 3: {Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation.}\n",
      "Which to keep <0-2>?: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: GorniakRoy04\n",
      "\t At Issue Key: pages\n",
      "\t<0>- Accepted: 429--470\n",
      "\t<1>- Duplicate 1: 429-470\n",
      "\t<2>- Duplicate 2: 429-470\n",
      "Which to keep <0-2>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: Krishnamurthy2013\n",
      "\t At Issue Key: journal\n",
      "\t<0>- Accepted: Transactions of the Association for Computational Linguistics\n",
      "\t<1>- Duplicate 1: Transactions of the Association for \\ldots\n",
      "\t<2>- Duplicate 2: Transactions of the Association for \\ldots\n",
      "Which to keep <0-2>?: 0\n",
      "\t At Issue Key: title\n",
      "\t<0>- Accepted: Jointly learning to parse and perceive: Connecting natural language to the physical world\n",
      "\t<1>- Duplicate 1: {Jointly learning to parse and perceive: Connecting natural language to the physical world}\n",
      "\t<2>- Duplicate 2: {Jointly learning to parse and perceive: Connecting natural language to the physical world}\n",
      "Which to keep <0-2>?: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: kulkarni2011baby\n",
      "\t At Issue Key: author\n",
      "\t<0>- Accepted: Kulkarni, Girish and Premraj, Visruth and Dhar, Sagnik and Li, Siming and Choi, Yejin and Berg, Alexander C. and Berg, Tamara L.\n",
      "\t<1>- Duplicate 1: Kulkarni, Girish and Premraj, Visruth and Dhar, Sagnik and Li, Siming and Choi, Yejin and Berg, Alexander C and Berg, Tamara L\n",
      "\t<2>- Duplicate 2: Kulkarni, Girish and Premraj, Visruth and Dhar, Sagnik and Li, Siming and Choi, Yejin and Berg, Alexander C and Berg, Tamara L\n",
      "Which to keep <0-2>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: Farhadi2009\n",
      "\t At Issue Key: author\n",
      "\t<0>- Accepted: Farhadi, Ali and Endres, Ian and Hoiem, Derek and Forsyth, David\n",
      "\t<1>- Duplicate 2: Farhadi, a. and Endres, I. and Hoiem, D. and Forsyth, D.\n",
      "Which to keep <0-1>?: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: Berlin1991\n",
      "\t At Issue Key: publisher\n",
      "\t<0>- Accepted: Univ of California Press\n",
      "\t<1>- Duplicate 1: University of California Press\n",
      "Which to keep <0-1>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: socher2011parsing\n",
      "\t At Issue Key: author\n",
      "\t<0>- Accepted: Socher, Richard and Lin, Cliff C. and Ng, Andrew and Manning, Chris\n",
      "\t<1>- Duplicate 2: Socher, Richard and Lin, Cliff C. and Ng, Andrew and Manning, Chris\n",
      "\t<2>- Duplicate 3: Socher, Richard and Lin, Cliff C. and Ng, Andrew and Manning, Chris\n",
      "\t<3>- Duplicate 4: Socher, Richard and Lin, Cliff C. and Ng, Andrew and Manning, Chris\n",
      "\t<4>- Duplicate 5: Socher, Richard and Lin, Cliff C. and Ng, Andrew and Manning, Chris\n",
      "\t<5>- Duplicate 6: Socher, Richard and Lin, Cliff C. and Ng, Andrew and Manning, Chris\n",
      "\t<6>- Duplicate 7: Socher, Richard and Lin, Cliff C. and Ng, Andrew and Manning, Chris\n",
      "Which to keep <0-6>?: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: Lassiter09a\n",
      "\t At Issue Key: pages\n",
      "\t<0>- Accepted: 127--150\n",
      "\t<1>- Duplicate 1: 127-150\n",
      "\t<2>- Duplicate 2: 127-150\n",
      "\t<3>- Duplicate 5: 127-150\n",
      "Which to keep <0-3>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+ Entry: Chen2008\n",
      "\t At Issue Key: author\n",
      "\t<0>- Accepted: Chen, David L and Mooney, Raymond J.\n",
      "\t<1>- Duplicate 1: Chen, David L and Mooney, Raymond J\n",
      "\t<2>- Duplicate 2: Chen, David L and Mooney, Raymond J\n",
      "Which to keep <0-2>?: 1\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*20)\n",
    "for entry_id, (good, bad) in fixes.items():\n",
    "        if len(bad) == 0: \n",
    "            continue\n",
    "        choices = {}\n",
    "        print(\"+ Entry: {}\".format(entry_id))\n",
    "        for k, v in bad.items():\n",
    "            print(\"\\t At Issue Key: {}\".format(k))\n",
    "            print(\"\\t<0>- Accepted: {}\".format(db.entries.index[entry_id][k]))\n",
    "            choices[0] = db.entries.index[entry_id][k]\n",
    "            for ii, vi in enumerate(v, 1):\n",
    "                print(\"\\t<{}>- Duplicate {}: {}\".format(ii, vi, dups[entry_id][vi][k]))\n",
    "                choices[ii] = dups[entry_id][vi][k]\n",
    "        \n",
    "            choice = int(input(\"Which to keep <0-{}>?: \".format(len(choices)-1)))\n",
    "            db.entries.index[entry_id][k] = choices[choice]\n",
    "        print(\"\\n\"*3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bw = pybib.bwriter.BibTexWriter()\n",
    "bw.order_entries_by = ('author', 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db2 = pybib.bibdatabase.BibDatabase()\n",
    "out = list(map(lambda x: dict(x.items()), db.entries.index.values()))\n",
    "for item in out:\n",
    "    item['url'] = item.pop(\"link\", \"#\")\n",
    "db2.entries = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@article{1311.3011,\n",
      " abstract = {The Cornell Semantic Parsing Framework (SPF) is a learning and inference\n",
      "framework for mapping natural language to formal representation of its meaning.},\n",
      " author = {Yoav Artzi},\n",
      " notes = {Empty},\n",
      " title = {Cornell SPF: Cornell Semantic Parsing Framework},\n",
      " url = {http://arxiv.org/abs/1311.3011v2},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{1502.03044,\n",
      " abstract = {Inspired by recent work in machine translation and object detection, we\n",
      "introduce an attention based model that automatically learns to describe the\n",
      "content of images. We describe how we can train this model in a deterministic\n",
      "manner using standard backpropagation techniques and stochastically by\n",
      "maximizing a variational lower bound. We also show through visualization how\n",
      "the model is able to automatically learn to fix its gaze on salient objects\n",
      "while generating the corresponding words in the output sequence. We validate\n",
      "the use of attention with state-of-the-art performance on three benchmark\n",
      "datasets: Flickr8k, Flickr30k and MS COCO.},\n",
      " author = {Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, Yoshua Bengio},\n",
      " notes = {Empty},\n",
      " title = {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},\n",
      " url = {http://arxiv.org/abs/1502.03044v3},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@article{1511.00060,\n",
      " abstract = {Long Short-Term Memory (LSTM) networks, a type of recurrent neural network\n",
      "with a more complex computational unit, have been successfully applied to a\n",
      "variety of sequence modeling tasks. In this paper we develop Tree Long\n",
      "Short-Term Memory (TreeLSTM), a neural network model based on LSTM, which is\n",
      "designed to predict a tree rather than a linear sequence. TreeLSTM defines the\n",
      "probability of a sentence by estimating the generation probability of its\n",
      "dependency tree. At each time step, a node is generated based on the\n",
      "representation of the generated sub-tree. We further enhance the modeling power\n",
      "of TreeLSTM by explicitly representing the correlations between left and right\n",
      "dependents. Application of our model to the MSR sentence completion challenge\n",
      "achieves results beyond the current state of the art. We also report results on\n",
      "dependency parsing reranking achieving competitive performance.},\n",
      " author = {Xingxing Zhang, Liang Lu, Mirella Lapata},\n",
      " notes = {Empty},\n",
      " title = {Top-down Tree Long Short-Term Memory Networks},\n",
      " url = {http://arxiv.org/abs/1511.00060v3},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@article{1602.07776,\n",
      " abstract = {We introduce recurrent neural network grammars, probabilistic models of\n",
      "sentences with explicit phrase structure. We explain efficient inference\n",
      "procedures that allow application to both parsing and language modeling.\n",
      "Experiments show that they provide better parsing in English than any single\n",
      "previously published supervised generative model and better language modeling\n",
      "than state-of-the-art sequential RNNs in English and Chinese.},\n",
      " author = {Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, Noah A. Smith},\n",
      " notes = {Empty},\n",
      " title = {Recurrent Neural Network Grammars},\n",
      " url = {http://arxiv.org/abs/1602.07776v3},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1603.06059,\n",
      " abstract = {There has been an explosion of work in the vision & language community during\n",
      "the past few years from image captioning to video transcription, and answering\n",
      "questions about images. These tasks have focused on literal descriptions of the\n",
      "image. To move beyond the literal, we choose to explore how questions about an\n",
      "image are often directed at commonsense inference and the abstract events\n",
      "evoked by objects in the image. In this paper, we introduce the novel task of\n",
      "Visual Question Generation (VQG), where the system is tasked with asking a\n",
      "natural and engaging question when shown an image. We provide three datasets\n",
      "which cover a variety of images from object-centric to event-centric, with\n",
      "considerably more abstract training data than provided to state-of-the-art\n",
      "captioning systems thus far. We train and test several generative and retrieval\n",
      "models to tackle the task of VQG. Evaluation results show that while such\n",
      "models ask reasonable questions for a variety of images, there is still a wide\n",
      "gap with human performance which motivates further work on connecting images\n",
      "with commonsense knowledge and pragmatics. Our proposed task offers a new\n",
      "challenge to the community which we hope furthers interest in exploring deeper\n",
      "connections between vision & language.},\n",
      " author = {Nasrin Mostafazadeh, Ishan Misra, Jacob Devlin, Margaret Mitchell, Xiaodong He, Lucy Vanderwende},\n",
      " notes = {Empty},\n",
      " title = {Generating Natural Questions About an Image},\n",
      " url = {http://arxiv.org/abs/1603.06059v3},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1604.00562,\n",
      " abstract = {We present a model for pragmatically describing scenes, in which contrastive\n",
      "behavior results from a combination of inference-driven pragmatics and learned\n",
      "semantics. Like previous learned approaches to language generation, our model\n",
      "uses a simple feature-driven architecture (here a pair of neural \"listener\" and\n",
      "\"speaker\" models) to ground language in the world. Like inference-driven\n",
      "approaches to pragmatics, our model actively reasons about listener behavior\n",
      "when selecting utterances. For training, our approach requires only ordinary\n",
      "captions, annotated _without_ demonstration of the pragmatic behavior the model\n",
      "ultimately exhibits. In human evaluations on a referring expression game, our\n",
      "approach succeeds 81% of the time, compared to a 69% success rate using\n",
      "existing techniques.},\n",
      " author = {Jacob Andreas, Dan Klein},\n",
      " notes = {Empty},\n",
      " title = {Reasoning About Pragmatics with Neural Listeners and Speakers},\n",
      " url = {http://arxiv.org/abs/1604.00562v2},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1604.03968,\n",
      " abstract = {We introduce the first dataset for sequential vision-to-language, and explore\n",
      "how this data may be used for the task of visual storytelling. The first\n",
      "release of this dataset, SIND v.1, includes 81,743 unique photos in 20,211\n",
      "sequences, aligned to both descriptive (caption) and story language. We\n",
      "establish several strong baselines for the storytelling task, and motivate an\n",
      "automatic metric to benchmark progress. Modelling concrete description as well\n",
      "as figurative and social language, as provided in this dataset and the\n",
      "storytelling task, has the potential to move artificial intelligence from basic\n",
      "understandings of typical visual scenes towards more and more human-like\n",
      "understanding of grounded event structure and subjective expression.},\n",
      " author = { Ting-Hao,  Huang, Francis Ferraro, Nasrin Mostafazadeh, Ishan Misra, Aishwarya Agrawal, Jacob Devlin, Ross Girshick, Xiaodong He, Pushmeet Kohli, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh, Lucy Vanderwende, Michel Galley, Margaret Mitchell},\n",
      " notes = {Empty},\n",
      " title = {Visual Storytelling},\n",
      " url = {http://arxiv.org/abs/1604.03968v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1604.04835,\n",
      " abstract = {Knowledge representation is an important, long-history topic in AI, and there\n",
      "have been a large amount of work for knowledge graph embedding which projects\n",
      "symbolic entities and relations into low-dimensional, real-valued vector space.\n",
      "However, most embedding methods merely concentrate on data fitting and ignore\n",
      "the explicit semantic expression, leading to uninterpretable representations.\n",
      "Thus, traditional embedding methods have limited potentials for many\n",
      "applications such as question answering, and entity classification. To this\n",
      "end, this paper proposes a semantic representation method for knowledge graph\n",
      "\\textbf{(KSR)}, which imposes a two-level hierarchical generative process that\n",
      "globally extracts many aspects and then locally assigns a specific category in\n",
      "each aspect for every triple. Since both aspects and categories are\n",
      "semantics-relevant, the collection of categories in each aspect is treated as\n",
      "the semantic representation of this triple. Extensive experiments justify our\n",
      "model outperforms other state-of-the-art baselines substantially.},\n",
      " author = {Han Xiao, Minlie Huang, Xiaoyan Zhu},\n",
      " notes = {Empty},\n",
      " title = {SSP: Semantic Space Projection for Knowledge Graph Embedding with Text Descriptions},\n",
      " url = {http://arxiv.org/abs/1604.04835v2},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1604.06045,\n",
      " abstract = {A long-term goal of machine learning research is to build an intelligent\n",
      "dialog agent. Most research in natural language understanding has focused on\n",
      "learning from fixed training sets of labeled data, with supervision either at\n",
      "the word level (tagging, parsing tasks) or sentence level (question answering,\n",
      "machine translation). This kind of supervision is not realistic of how humans\n",
      "learn, where language is both learned by, and used for, communication. In this\n",
      "work, we study dialog-based language learning, where supervision is given\n",
      "naturally and implicitly in the response of the dialog partner during the\n",
      "conversation. We study this setup in two domains: the bAbI dataset of (Weston\n",
      "et al., 2015) and large-scale question answering from (Dodge et al., 2015). We\n",
      "evaluate a set of baseline learning strategies on these tasks, and show that a\n",
      "novel model incorporating predictive lookahead is a promising approach for\n",
      "learning from a teacher's response. In particular, a surprising result is that\n",
      "it can learn to answer questions correctly without any reward-based supervision\n",
      "at all.},\n",
      " author = {Jason Weston},\n",
      " notes = {Empty},\n",
      " title = {Dialog-based Language Learning},\n",
      " url = {http://arxiv.org/abs/1604.06045v7},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1606.03632,\n",
      " abstract = {Natural language generation plays a critical role in any spoken dialogue\n",
      "system. We present a new approach to natural language generation using\n",
      "recurrent neural networks in an encoder-decoder framework. In contrast with\n",
      "previous work, our model uses both lexicalized and delexicalized versions of\n",
      "slot-value pairs for each dialogue act. This allows our model to learn from all\n",
      "available data, rather than being restricted to learning only from\n",
      "delexicalized slot-value pairs. We show that this helps our model generate more\n",
      "natural sentences with better grammar. We further improve our model's\n",
      "performance by initializing its weights from a pretrained language model. Human\n",
      "evaluation of our best-performing model indicates that it generates sentences\n",
      "which users find more natural and appealing.},\n",
      " author = {Shikhar Sharma, Jing He, Kaheer Suleman, Hannes Schulz, Philip Bachman},\n",
      " notes = {Empty},\n",
      " title = {Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data},\n",
      " url = {http://arxiv.org/abs/1606.03632v2},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1606.03821,\n",
      " abstract = {The production of color language is essential for grounded language\n",
      "generation. Color descriptions have many challenging properties: they can be\n",
      "vague, compositionally complex, and denotationally rich. We present an\n",
      "effective approach to generating color descriptions using recurrent neural\n",
      "networks and a Fourier-transformed color representation. Our model outperforms\n",
      "previous work on a conditional language modeling task over a large corpus of\n",
      "naturalistic color descriptions. In addition, probing the model's output\n",
      "reveals that it can accurately produce not only basic color terms but also\n",
      "descriptors with non-convex denotations (\"greenish\"), bare modifiers (\"bright\",\n",
      "\"dull\"), and compositional phrases (\"faded teal\") not seen in training.},\n",
      " author = {Will Monroe, Noah D. Goodman, Christopher Potts},\n",
      " notes = {Empty},\n",
      " title = {Learning to Generate Compositional Color Descriptions},\n",
      " url = {http://arxiv.org/abs/1606.03821v2},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1606.04052,\n",
      " abstract = {In an end-to-end dialog system, the aim of dialog state tracking is to\n",
      "accurately estimate a compact representation of the current dialog status from\n",
      "a sequence of noisy observations produced by the speech recognition and the\n",
      "natural language understanding modules. This paper introduces a novel method of\n",
      "dialog state tracking based on the general paradigm of machine reading and\n",
      "proposes to solve it using an End-to-End Memory Network, MemN2N, a\n",
      "memory-enhanced neural network architecture. We evaluate the proposed approach\n",
      "on the second Dialog State Tracking Challenge (DSTC-2) dataset. The corpus has\n",
      "been converted for the occasion in order to frame the hidden state variable\n",
      "inference as a question-answering task based on a sequence of utterances\n",
      "extracted from a dialog. We show that the proposed tracker gives encouraging\n",
      "results. Then, we propose to extend the DSTC-2 dataset with specific reasoning\n",
      "capabilities requirement like counting, list maintenance, yes-no question\n",
      "answering and indefinite knowledge management. Finally, we present encouraging\n",
      "results using our proposed MemN2N based tracking model.},\n",
      " author = {Julien Perez, Fei Liu},\n",
      " notes = {Empty},\n",
      " title = {Dialog state tracking, a machine reading approach using Memory Network},\n",
      " url = {http://arxiv.org/abs/1606.04052v4},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1607.01426,\n",
      " abstract = {Our goal is to combine the rich multistep inference of symbolic logical\n",
      "reasoning with the generalization capabilities of neural networks. We are\n",
      "particularly interested in complex reasoning about entities and relations in\n",
      "text and large-scale knowledge bases (KBs). Neelakantan et al. (2015) use RNNs\n",
      "to compose the distributed semantics of multi-hop paths in KBs; however for\n",
      "multiple reasons, the approach lacks accuracy and practicality. This paper\n",
      "proposes three significant modeling advances: (1) we learn to jointly reason\n",
      "about relations, entities, and entity-types; (2) we use neural attention\n",
      "modeling to incorporate multiple paths; (3) we learn to share strength in a\n",
      "single RNN that represents logical composition across all relations. On a\n",
      "largescale Freebase+ClueWeb prediction task, we achieve 25% error reduction,\n",
      "and a 53% error reduction on sparse relations due to shared strength. On chains\n",
      "of reasoning in WordNet we reduce error in mean quantile by 84% versus previous\n",
      "state-of-the-art. The code and data are available at\n",
      "https://rajarshd.github.io/ChainsofReasoning},\n",
      " author = {Rajarshi Das, Arvind Neelakantan, David Belanger, Andrew McCallum},\n",
      " notes = {Empty},\n",
      " title = {Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks},\n",
      " url = {http://arxiv.org/abs/1607.01426v2},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1608.00525,\n",
      " abstract = {Referring expressions usually describe an object using properties of the\n",
      "object and relationships of the object with other objects. We propose a\n",
      "technique that integrates context between objects to understand referring\n",
      "expressions. Our approach uses an LSTM to learn the probability of a referring\n",
      "expression, with input features from a region and a context region. The context\n",
      "regions are discovered using multiple-instance learning (MIL) since annotations\n",
      "for context objects are generally not available for training. We utilize\n",
      "max-margin based MIL objective functions for training the LSTM. Experiments on\n",
      "the Google RefExp and UNC RefExp datasets show that modeling context between\n",
      "objects provides better performance than modeling only object properties. We\n",
      "also qualitatively show that our technique can ground a referring expression to\n",
      "its referred region along with the supporting context region.},\n",
      " author = {Varun K. Nagaraja, Vlad I. Morariu, Larry S. Davis},\n",
      " notes = {Empty},\n",
      " title = {Modeling Context Between Objects for Referring Expression Understanding},\n",
      " url = {http://arxiv.org/abs/1608.00525v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1608.05813,\n",
      " abstract = {A picture is worth a thousand words. Not until recently, however, we noticed\n",
      "some success stories in understanding of visual scenes: a model that is able to\n",
      "detect/name objects, describe their attributes, and recognize their\n",
      "relationships/interactions. In this paper, we propose a phrase-based\n",
      "hierarchical Long Short-Term Memory (phi-LSTM) model to generate image\n",
      "description. The proposed model encodes sentence as a sequence of combination\n",
      "of phrases and words, instead of a sequence of words alone as in those\n",
      "conventional solutions. The two levels of this model are dedicated to i) learn\n",
      "to generate image relevant noun phrases, and ii) produce appropriate image\n",
      "description from the phrases and other words in the corpus. Adopting a\n",
      "convolutional neural network to learn image features and the LSTM to learn the\n",
      "word sequence in a sentence, the proposed model has shown better or competitive\n",
      "results in comparison to the state-of-the-art models on Flickr8k and Flickr30k\n",
      "datasets.},\n",
      " author = {Ying Hua Tan, Chee Seng Chan},\n",
      " notes = {Empty},\n",
      " title = {phi-LSTM: A Phrase-based Hierarchical LSTM Model for Image Captioning},\n",
      " url = {http://arxiv.org/abs/1608.05813v3},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1609.00777,\n",
      " abstract = {This paper proposes \\emph{KB-InfoBot}---a dialogue agent that provides users\n",
      "with an entity from a knowledge base (KB) by interactively asking for its\n",
      "attributes. All components of the KB-InfoBot are trained in an end-to-end\n",
      "fashion using reinforcement learning. Goal-oriented dialogue systems typically\n",
      "need to interact with an external database to access real-world knowledge (e.g.\n",
      "movies playing in a city). Previous systems achieved this by issuing a symbolic\n",
      "query to the database and adding retrieved results to the dialogue state.\n",
      "However, such symbolic operations break the differentiability of the system and\n",
      "prevent end-to-end training of neural dialogue agents. In this paper, we\n",
      "address this limitation by replacing symbolic queries with an induced \"soft\"\n",
      "posterior distribution over the KB that indicates which entities the user is\n",
      "interested in. We also provide a modified version of the episodic REINFORCE\n",
      "algorithm, which allows the KB-InfoBot to explore and learn both the policy for\n",
      "selecting dialogue acts and the posterior over the KB for retrieving the\n",
      "correct entities. Experimental results show that the end-to-end trained\n",
      "KB-InfoBot outperforms competitive rule-based baselines, as well as agents\n",
      "which are not end-to-end trainable.},\n",
      " author = {Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng},\n",
      " notes = {Empty},\n",
      " title = {End-to-End Reinforcement Learning of Dialogue Agents for Information Access},\n",
      " url = {http://arxiv.org/abs/1609.00777v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1609.03286,\n",
      " abstract = {Natural language understanding (NLU) is a core component of a spoken dialogue\n",
      "system. Recently recurrent neural networks (RNN) obtained strong results on NLU\n",
      "due to their superior ability of preserving sequential information over time.\n",
      "Traditionally, the NLU module tags semantic slots for utterances considering\n",
      "their flat structures, as the underlying RNN structure is a linear chain.\n",
      "However, natural language exhibits linguistic properties that provide rich,\n",
      "structured information for better understanding. This paper introduces a novel\n",
      "model, knowledge-guided structural attention networks (K-SAN), a generalization\n",
      "of RNN to additionally incorporate non-flat network topologies guided by prior\n",
      "knowledge. There are two characteristics: 1) important substructures can be\n",
      "captured from small training data, allowing the model to generalize to\n",
      "previously unseen test data; 2) the model automatically figures out the salient\n",
      "substructures that are essential to predict the semantic tags of the given\n",
      "sentences, so that the understanding performance can be improved. The\n",
      "experiments on the benchmark Air Travel Information System (ATIS) data show\n",
      "that the proposed K-SAN architecture can effectively extract salient knowledge\n",
      "from substructures with an attention mechanism, and outperform the performance\n",
      "of the state-of-the-art neural network based frameworks.},\n",
      " author = {Yun-Nung Chen, Dilek Hakkani-Tur, Gokhan Tur, Asli Celikyilmaz, Jianfeng Gao, Li Deng},\n",
      " notes = {Empty},\n",
      " title = {Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks},\n",
      " url = {http://arxiv.org/abs/1609.03286v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1609.03441,\n",
      " abstract = {We present a dependency parser implemented as a single deep neural network\n",
      "that reads orthographic representations of words and directly generates\n",
      "dependencies and their labels. Unlike typical approaches to parsing, the model\n",
      "doesn't require part-of-speech (POS) tagging of the sentences. With proper\n",
      "regularization and additional supervision achieved with multitask learning we\n",
      "reach state-of-the-art performance on Slavic languages from the Universal\n",
      "Dependencies treebank: with no linguistic features other than characters, our\n",
      "parser is as accurate as a transition- based system trained on perfect POS\n",
      "tags.},\n",
      " author = {Jan Chorowski, Michał Zapotoczny, Paweł Rychlikowski},\n",
      " notes = {Empty},\n",
      " title = {Read, Tag, and Parse All at Once, or Fully-neural Dependency Parsing},\n",
      " url = {http://arxiv.org/abs/1609.03441v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1609.03528,\n",
      " abstract = {We describe Microsoft's conversational speech recognition system, in which we\n",
      "combine recent developments in neural-network-based acoustic and language\n",
      "modeling to advance the state of the art on the Switchboard recognition task.\n",
      "Inspired by machine learning ensemble techniques, the system uses a range of\n",
      "convolutional and recurrent neural networks. I-vector modeling and lattice-free\n",
      "MMI training provide significant gains for all acoustic model architectures.\n",
      "Language model rescoring with multiple forward and backward running RNNLMs, and\n",
      "word posterior-based system combination provide a 20% boost. The best single\n",
      "system uses a ResNet architecture acoustic model with RNNLM rescoring, and\n",
      "achieves a word error rate of 6.9% on the NIST 2000 Switchboard task. The\n",
      "combined system has an error rate of 6.3%, representing an improvement over\n",
      "previously reported results on this benchmark task.},\n",
      " author = {W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig},\n",
      " notes = {Empty},\n",
      " title = {The Microsoft 2016 Conversational Speech Recognition System},\n",
      " url = {http://arxiv.org/abs/1609.03528v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1609.05511,\n",
      " abstract = {Multilinear Grammar (MLG) is an approach to integrating the many different\n",
      "syntagmatic structures of language into a coherent architecture, the\n",
      "Rank-Interpretation Architecture. The architecture defines ranks from discourse\n",
      "structure through utterances, phrasal structures, word structures to speech\n",
      "sounds. Each rank has its own specific kind of prosodic-phonetic interpretation\n",
      "and semantic-pragmatic interpretation. Common to models of all these subdomains\n",
      "are models based on regular languages, and processors with finite working\n",
      "memory.},\n",
      " author = {Dafydd Gibbon, Sascha Griffiths},\n",
      " notes = {Empty},\n",
      " title = {Multilinear Grammar: Ranks and Interpretations},\n",
      " url = {http://arxiv.org/abs/1609.05511v3},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1609.07451,\n",
      " abstract = {The task of AMR-to-text generation is to generate grammatical text that\n",
      "sustains the semantic meaning for a given AMR graph. We at- tack the task by\n",
      "first partitioning the AMR graph into smaller fragments, and then generating\n",
      "the translation for each fragment, before finally deciding the order by solving\n",
      "an asymmetric generalized traveling salesman problem (AGTSP). A Maximum Entropy\n",
      "classifier is trained to estimate the traveling costs, and a TSP solver is used\n",
      "to find the optimized solution. The final model reports a BLEU score of 22.44\n",
      "on the SemEval-2016 Task8 dataset.},\n",
      " author = {Linfeng Song, Yue Zhang, Xiaochang Peng, Zhiguo Wang, Daniel Gildea},\n",
      " notes = {Empty},\n",
      " title = {AMR-to-text generation as a Traveling Salesman Problem},\n",
      " url = {http://arxiv.org/abs/1609.07451v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1609.08777,\n",
      " abstract = {We present a neural network architecture to predict a point in color space\n",
      "from the sequence of characters in the color's name. Using large scale\n",
      "color--name pairs obtained from an online color design forum, we evaluate our\n",
      "model on a \"color Turing test\" and find that, given a name, the colors\n",
      "predicted by our model are preferred by annotators to color names created by\n",
      "humans. Our datasets and demo system are available online at\n",
      "http://colorlab.us.},\n",
      " author = {Kazuya Kawakami, Chris Dyer, Bryan R. Routledge, Noah A. Smith},\n",
      " notes = {Empty},\n",
      " title = {Character Sequence Models for ColorfulWords},\n",
      " url = {http://arxiv.org/abs/1609.08777v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.02424,\n",
      " abstract = {Neural sequence models are widely used to model time-series data in many\n",
      "fields. Equally ubiquitous is the usage of beam search (BS) as an approximate\n",
      "inference algorithm to decode output sequences from these models. BS explores\n",
      "the search space in a greedy left-right fashion retaining only the top-$B$\n",
      "candidates -- resulting in sequences that differ only slightly from each other.\n",
      "Producing lists of nearly identical sequences is not only computationally\n",
      "wasteful but also typically fails to capture the inherent ambiguity of complex\n",
      "AI tasks. To overcome this problem, we propose \\emph{Diverse Beam Search}\n",
      "(DBS), an alternative to BS that decodes a list of diverse outputs by\n",
      "optimizing for a diversity-augmented objective. We observe that our method\n",
      "finds better top-1 solutions by controlling for the exploration and\n",
      "exploitation of the search space -- implying that DBS is a \\emph{better search\n",
      "algorithm}. Moreover, these gains are achieved with minimal computational or\n",
      "memory overhead as compared to beam search. To demonstrate the broad\n",
      "applicability of our method, we present results on image captioning, machine\n",
      "translation and visual question generation using both standard quantitative\n",
      "metrics and qualitative human studies. Our method consistently outperforms BS\n",
      "and previously proposed techniques for diverse decoding from neural sequence\n",
      "models.},\n",
      " author = {Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R. Selvaraju, Qing Sun, Stefan Lee, David Crandall, Dhruv Batra},\n",
      " notes = {Empty},\n",
      " title = {Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models},\n",
      " url = {http://arxiv.org/abs/1610.02424v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.02544,\n",
      " abstract = {A linking theory explains how verbs' semantic arguments are mapped to their\n",
      "syntactic arguments---the inverse of the Semantic Role Labeling task from the\n",
      "shallow semantic parsing literature. In this paper, we develop the\n",
      "Computational Linking Theory framework as a method for implementing and testing\n",
      "linking theories proposed in the theoretical literature. We deploy this\n",
      "framework to assess two cross-cutting types of linking theory: local v. global\n",
      "models and categorical v. featural models. To further investigate the behavior\n",
      "of these models, we develop a measurement model in the spirit of previous work\n",
      "in semantic role induction: the Semantic Proto-Role Linking Model. We use this\n",
      "model, which implements a generalization of Dowty's seminal Proto-Role Theory,\n",
      "to induce semantic proto-roles, which we compare to those Dowty proposes.},\n",
      " author = {Aaron Steven White, Drew Reisinger, Rachel Rudinger, Kyle Rawlins, Benjamin Van Durme},\n",
      " notes = {Empty},\n",
      " title = {Computational linking theory},\n",
      " url = {http://arxiv.org/abs/1610.02544v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.02692,\n",
      " abstract = {This thesis report studies methods to solve Visual Question-Answering (VQA)\n",
      "tasks with a Deep Learning framework. As a preliminary step, we explore Long\n",
      "Short-Term Memory (LSTM) networks used in Natural Language Processing (NLP) to\n",
      "tackle Question-Answering (text based). We then modify the previous model to\n",
      "accept an image as an input in addition to the question. For this purpose, we\n",
      "explore the VGG-16 and K-CNN convolutional neural networks to extract visual\n",
      "features from the image. These are merged with the word embedding or with a\n",
      "sentence embedding of the question to predict the answer. This work was\n",
      "successfully submitted to the Visual Question Answering Challenge 2016, where\n",
      "it achieved a 53,62% of accuracy in the test dataset. The developed software\n",
      "has followed the best programming practices and Python code style, providing a\n",
      "consistent baseline in Keras for different configurations.},\n",
      " author = {Issey Masuda, Santiago Pascual de la Puente, Xavier Giro-i-Nieto},\n",
      " notes = {Empty},\n",
      " title = {Open-Ended Visual Question-Answering},\n",
      " url = {http://arxiv.org/abs/1610.02692v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.02806,\n",
      " abstract = {We describe an attentive encoder that combines tree-structured recursive\n",
      "neural networks and sequential recurrent neural networks for modelling sentence\n",
      "pairs. Since existing attentive models exert attention on the sequential\n",
      "structure, we propose a way to incorporate attention into the tree topology.\n",
      "Specially, given a pair of sentences, our attentive encoder uses the\n",
      "representation of one sentence, which generated via an RNN, to guide the\n",
      "structural encoding of the other sentence on the dependency parse tree. We\n",
      "evaluate the proposed attentive encoder on three tasks: semantic similarity,\n",
      "paraphrase identification and true-false question selection. Experimental\n",
      "results show that our encoder outperforms all baselines and achieves\n",
      "state-of-the-art results on two tasks.},\n",
      " author = {Yao Zhou, Cong Liu, Yan Pan},\n",
      " notes = {Empty},\n",
      " title = {Modelling Sentence Pairs with Tree-structured Attentive Encoder},\n",
      " url = {http://arxiv.org/abs/1610.02806v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.02891,\n",
      " abstract = {It is difficult to train a personalized task-oriented dialogue system because\n",
      "the data collected from each individual is often insufficient. Personalized\n",
      "dialogue systems trained on a small dataset can overfit and make it difficult\n",
      "to adapt to different user needs. One way to solve this problem is to consider\n",
      "a collection of multiple users' data as a source domain and an individual\n",
      "user's data as a target domain, and to perform a transfer learning from the\n",
      "source to the target domain. By following this idea, we propose\n",
      "\"PETAL\"(PErsonalized Task-oriented diALogue), a transfer-learning framework\n",
      "based on POMDP to learn a personalized dialogue system. The system first learns\n",
      "common dialogue knowledge from the source domain and then adapts this knowledge\n",
      "to the target user. This framework can avoid the negative transfer problem by\n",
      "considering differences between source and target users. The policy in the\n",
      "personalized POMDP can learn to choose different actions appropriately for\n",
      "different users. Experimental results on a real-world coffee-shopping data and\n",
      "simulation data show that our personalized dialogue system can choose different\n",
      "optimal actions for different users, and thus effectively improve the dialogue\n",
      "quality under the personalized setting.},\n",
      " author = {Kaixiang Mo, Shuangyin Li, Yu Zhang, Jiajun Li, Qiang Yang},\n",
      " notes = {Empty},\n",
      " title = {Personalizing a Dialogue System with Transfer Learning},\n",
      " url = {http://arxiv.org/abs/1610.02891v2},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.02906,\n",
      " abstract = {This paper investigates the problem of network embedding, which aims at\n",
      "learning low-dimensional vector representation of nodes in networks. Most\n",
      "existing network embedding methods rely solely on the network structure, i.e.,\n",
      "the linkage relationships between nodes, but ignore the rich content\n",
      "information associated with it, which is common in real world networks and\n",
      "beneficial to describing the characteristics of a node. In this paper, we\n",
      "propose content-enhanced network embedding (CENE), which is capable of jointly\n",
      "leveraging the network structure and the content information. Our approach\n",
      "integrates text modeling and structure modeling in a general framework by\n",
      "treating the content information as a special kind of node. Experiments on\n",
      "several real world net- works with application to node classification show that\n",
      "our models outperform all existing network embedding methods, demonstrating the\n",
      "merits of content information and joint learning.},\n",
      " author = {Xiaofei Sun, Jiang Guo, Xiao Ding, Ting Liu},\n",
      " notes = {Empty},\n",
      " title = {A General Framework for Content-enhanced Network Representation Learning},\n",
      " url = {http://arxiv.org/abs/1610.02906v3},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.03035,\n",
      " abstract = {We present the Latent Sequence Decompositions (LSD) framework. LSD decomposes\n",
      "sequences with variable lengthed output units as a function of both the input\n",
      "sequence and the output sequence. We present a training algorithm which samples\n",
      "valid extensions and an approximate decoding algorithm. We experiment with the\n",
      "Wall Street Journal speech recognition task. Our LSD model achieves 12.9% WER\n",
      "compared to a character baseline of 14.8% WER. When combined with a\n",
      "convolutional network on the encoder, we achieve 9.2% WER.},\n",
      " author = {William Chan, Yu Zhang, Quoc Le, Navdeep Jaitly},\n",
      " notes = {Empty},\n",
      " title = {Latent Sequence Decompositions},\n",
      " url = {http://arxiv.org/abs/1610.03035v2},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.04211,\n",
      " abstract = {Machine reading using differentiable reasoning models has recently shown\n",
      "remarkable progress. In this context, End-to-End trainable Memory Networks,\n",
      "MemN2N, have demonstrated promising performance on simple natural language\n",
      "based reasoning tasks such as factual reasoning and basic deduction. However,\n",
      "other tasks, namely multi-fact question-answering, positional reasoning or\n",
      "dialog related tasks, remain challenging particularly due to the necessity of\n",
      "more complex interactions between the memory and controller modules composing\n",
      "this family of models. In this paper, we introduce a novel end-to-end memory\n",
      "access regulation mechanism inspired by the current progress on the connection\n",
      "short-cutting principle in the field of computer vision. Concretely, we develop\n",
      "a Gated End-to-End trainable Memory Network architecture, GMemN2N. From the\n",
      "machine learning perspective, this new capability is learned in an end-to-end\n",
      "fashion without the use of any additional supervision signal which is, as far\n",
      "as our knowledge goes, the first of its kind. Our experiments show significant\n",
      "improvements on the most challenging tasks in the 20 bAbI dataset, without the\n",
      "use of any domain knowledge. Then, we show improvements on the dialog bAbI\n",
      "tasks including the real human-bot conversion-based Dialog State Tracking\n",
      "Challenge (DSTC-2) dataset. On these two datasets, our model sets the new state\n",
      "of the art.},\n",
      " author = {Julien Perez, Fei Liu},\n",
      " notes = {Empty},\n",
      " title = {Gated End-to-End Memory Networks},\n",
      " url = {http://arxiv.org/abs/1610.04211v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.06454,\n",
      " abstract = {Hypothesis testing is an important cognitive process that supports human\n",
      "reasoning. In this paper, we introduce a computational hypothesis testing\n",
      "approach based on memory augmented neural networks. Our approach involves a\n",
      "hypothesis testing loop that reconsiders and progressively refines a previously\n",
      "formed hypothesis in order to generate new hypotheses to test. We apply the\n",
      "proposed approach to language comprehension task by using Neural Semantic\n",
      "Encoders (NSE). Our NSE models achieve the state-of-the-art results showing an\n",
      "absolute improvement of 1.2% to 2.6% accuracy over previous results obtained by\n",
      "single and ensemble systems on standard machine comprehension benchmarks such\n",
      "as the Children's Book Test (CBT) and Who-Did-What (WDW) news article datasets.},\n",
      " author = {Tsendsuren Munkhdalai, Hong Yu},\n",
      " notes = {Empty},\n",
      " title = {Reasoning with Memory Augmented Neural Networks for Language Comprehension},\n",
      " url = {http://arxiv.org/abs/1610.06454v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.07149,\n",
      " abstract = {Open-domain human-computer conversation has attracted much attention in the\n",
      "field of NLP. Contrary to rule- or template-based domain-specific dialog\n",
      "systems, open-domain conversation usually requires data-driven approaches,\n",
      "which can be roughly divided into two categories: retrieval-based and\n",
      "generation-based systems. Retrieval systems search a user-issued utterance\n",
      "(called a query) in a large database, and return a reply that best matches the\n",
      "query. Generative approaches, typically based on recurrent neural networks\n",
      "(RNNs), can synthesize new replies, but they suffer from the problem of\n",
      "generating short, meaningless utterances. In this paper, we propose a novel\n",
      "ensemble of retrieval-based and generation-based dialog systems in the open\n",
      "domain. In our approach, the retrieved candidate, in addition to the original\n",
      "query, is fed to an RNN-based reply generator, so that the neural model is\n",
      "aware of more information. The generated reply is then fed back as a new\n",
      "candidate for post-reranking. Experimental results show that such ensemble\n",
      "outperforms each single part of it by a large margin.},\n",
      " author = {Yiping Song, Rui Yan, Xiang Li, Dongyan Zhao, Ming Zhang},\n",
      " notes = {Empty},\n",
      " title = {Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems},\n",
      " url = {http://arxiv.org/abs/1610.07149v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.07365,\n",
      " abstract = {This special issue is dedicated to get a better picture of the relationships\n",
      "between computational linguistics and cognitive science. It specifically raises\n",
      "two questions: \"what is the potential contribution of computational language\n",
      "modeling to cognitive science?\" and conversely: \"what is the influence of\n",
      "cognitive science in contemporary computational linguistics?\"},\n",
      " author = {Thierry Poibeau, Shravan Vasishth},\n",
      " notes = {Empty},\n",
      " title = {Introduction: Cognitive Issues in Natural Language Processing},\n",
      " url = {http://arxiv.org/abs/1610.07365v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.07432,\n",
      " abstract = {Meaning has been called the \"holy grail\" of a variety of scientific\n",
      "disciplines, ranging from linguistics to philosophy, psychology and the\n",
      "neurosciences. The field of Artifical Intelligence (AI) is very much a part of\n",
      "that list: the development of sophisticated natural language semantics is a\n",
      "sine qua non for achieving a level of intelligence comparable to humans.\n",
      "Embodiment theories in cognitive science hold that human semantic\n",
      "representation depends on sensori-motor experience; the abundant evidence that\n",
      "human meaning representation is grounded in the perception of physical reality\n",
      "leads to the conclusion that meaning must depend on a fusion of multiple\n",
      "(perceptual) modalities. Despite this, AI research in general, and its\n",
      "subdisciplines such as computational linguistics and computer vision in\n",
      "particular, have focused primarily on tasks that involve a single modality.\n",
      "Here, we propose virtual embodiment as an alternative, long-term strategy for\n",
      "AI research that is multi-modal in nature and that allows for the kind of\n",
      "scalability required to develop the field coherently and incrementally, in an\n",
      "ethically responsible fashion.},\n",
      " author = {Douwe Kiela, Luana Bulat, Anita L. Vero, Stephen Clark},\n",
      " notes = {Empty},\n",
      " title = {Virtual Embodiment: A Scalable Long-Term Strategy for Artificial Intelligence Research},\n",
      " url = {http://arxiv.org/abs/1610.07432v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.07569,\n",
      " abstract = {Vector representations of words have heralded a transformational approach to\n",
      "classical problems in NLP; the most popular example is word2vec. However, a\n",
      "single vector does not suffice to model the polysemous nature of many\n",
      "(frequent) words, i.e., words with multiple meanings. In this paper, we propose\n",
      "a three-fold approach for unsupervised polysemy modeling: (a) context\n",
      "representations, (b) sense induction and disambiguation and (c) lexeme (as a\n",
      "word and sense pair) representations. A key feature of our work is the finding\n",
      "that a sentence containing a target word is well represented by a low rank\n",
      "subspace, instead of a point in a vector space. We then show that the subspaces\n",
      "associated with a particular sense of the target word tend to intersect over a\n",
      "line (one-dimensional subspace), which we use to disambiguate senses using a\n",
      "clustering algorithm that harnesses the Grassmannian geometry of the\n",
      "representations. The disambiguation algorithm, which we call $K$-Grassmeans,\n",
      "leads to a procedure to label the different senses of the target word in the\n",
      "corpus -- yielding lexeme vector representations, all in an unsupervised manner\n",
      "starting from a large (Wikipedia) corpus in English. Apart from several\n",
      "prototypical target (word,sense) examples and a host of empirical studies to\n",
      "intuit and justify the various geometric representations, we validate our\n",
      "algorithms on standard sense induction and disambiguation datasets and present\n",
      "new state-of-the-art results.},\n",
      " author = {Jiaqi Mu, Suma Bhat, Pramod Viswanath},\n",
      " notes = {Empty},\n",
      " title = {Geometry of Polysemy},\n",
      " url = {http://arxiv.org/abs/1610.07569v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.07647,\n",
      " abstract = {Multi-hop inference is necessary for machine learning systems to successfully\n",
      "solve tasks such as Recognising Textual Entailment and Machine Reading. In this\n",
      "work, we demonstrate the effectiveness of adaptive computation for learning the\n",
      "number of inference steps required for examples of different complexity and\n",
      "that learning the correct number of inference steps is difficult. We introduce\n",
      "the first model involving Adaptive Computation Time which provides a small\n",
      "performance benefit on top of a similar model without an adaptive component as\n",
      "well as enabling considerable insight into the reasoning process of the model.},\n",
      " author = {Mark Neumann, Pontus Stenetorp, Sebastian Riedel},\n",
      " notes = {Empty},\n",
      " title = {Learning to Reason With Adaptive Computation},\n",
      " url = {http://arxiv.org/abs/1610.07647v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.07708,\n",
      " abstract = {Machine Learning has been a big success story during the AI resurgence. One\n",
      "particular stand out success relates to unsupervised learning from a massive\n",
      "amount of data, albeit much of it relates to one modality/type of data at a\n",
      "time. In spite of early assertions of the unreasonable effectiveness of data,\n",
      "there is increasing recognition of utilizing knowledge whenever it is available\n",
      "or can be created purposefully. In this paper, we focus on discussing the\n",
      "indispensable role of knowledge for deeper understanding of complex text and\n",
      "multimodal data in situations where (i) large amounts of training data\n",
      "(labeled/unlabeled) are not available or labor intensive to create, (ii) the\n",
      "objects (particularly text) to be recognized are complex (i.e., beyond simple\n",
      "entity-person/location/organization names), such as implicit entities and\n",
      "highly subjective content, and (iii) applications need to use complementary or\n",
      "related data in multiple modalities/media. What brings us to the cusp of rapid\n",
      "progress is our ability to (a) create knowledge, varying from comprehensive or\n",
      "cross domain to domain or application specific, and (b) carefully exploit the\n",
      "knowledge to further empower or extend the applications of ML/NLP techniques.\n",
      "Using the early results in several diverse situations - both in data types and\n",
      "applications - we seek to foretell unprecedented progress in our ability for\n",
      "deeper understanding and exploitation of multimodal data.},\n",
      " author = {Amit Sheth, Sujan Perera, Sanjaya Wijeratne},\n",
      " notes = {Empty},\n",
      " title = {Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples},\n",
      " url = {http://arxiv.org/abs/1610.07708v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.07710,\n",
      " abstract = {Emoji are a contemporary and extremely popular way to enhance electronic\n",
      "communication. Without rigid semantics attached to them, emoji symbols take on\n",
      "different meanings based on the context of a message. Thus, like the word sense\n",
      "disambiguation task in natural language processing, machines also need to\n",
      "disambiguate the meaning or sense of an emoji. In a first step toward achieving\n",
      "this goal, this paper presents EmojiNet, the first machine readable sense\n",
      "inventory for emoji. EmojiNet is a resource enabling systems to link emoji with\n",
      "their context-specific meaning. It is automatically constructed by integrating\n",
      "multiple emoji resources with BabelNet, which is the most comprehensive\n",
      "multilingual sense inventory available to date. The paper discusses its\n",
      "construction, evaluates the automatic resource creation process, and presents a\n",
      "use case where EmojiNet disambiguates emoji usage in tweets. EmojiNet is\n",
      "available online for use at http://emojinet.knoesis.org.},\n",
      " author = {Sanjaya Wijeratne, Lakshika Balasuriya, Amit Sheth, Derek Doran},\n",
      " notes = {Empty},\n",
      " title = {EmojiNet: Building a Machine Readable Sense Inventory for Emoji},\n",
      " url = {http://arxiv.org/abs/1610.07710v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{1610.07918,\n",
      " abstract = {We describe and analyze a simple and effective algorithm for sequence\n",
      "segmentation applied to speech processing tasks. We propose a neural\n",
      "architecture that is composed of two modules trained jointly: a recurrent\n",
      "neural network (RNN) module and a structured prediction model. The RNN outputs\n",
      "are considered as feature functions to the structured model. The overall model\n",
      "is trained with a structured loss function which can be designed to the given\n",
      "segmentation task. We demonstrate the effectiveness of our method by applying\n",
      "it to two simple tasks commonly used in phonetic studies: word segmentation and\n",
      "voice onset time segmentation. Results sug- gest the proposed model is superior\n",
      "to previous methods, ob- taining state-of-the-art results on the tested\n",
      "datasets.},\n",
      " author = {Yossi Adi, Joseph Keshet, Emily Cibelli, Matthew Goldrick},\n",
      " notes = {Empty},\n",
      " title = {Sequence Segmentation Using Joint RNN and Structured Prediction Models},\n",
      " url = {http://arxiv.org/abs/1610.07918v1},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@inproceedings{abbeel2004apprenticeship,\n",
      " abstract = {We consider learning in a Markov decision\n",
      "process where we are not explicitly given a reward\n",
      "function, but where instead we can observe\n",
      "an expert demonstrating the task that\n",
      "we want to learn to perform. This setting\n",
      "is useful in applications (such as the task of\n",
      "driving) where it may be difficult to write\n",
      "down an explicit reward function specifying\n",
      "exactly how different desiderata should be\n",
      "traded off. We think of the expert as trying\n",
      "to maximize a reward function that is expressible\n",
      "as a linear combination of known\n",
      "features, and give an algorithm for learning\n",
      "the task demonstrated by the expert. Our algorithm\n",
      "is based on using “inverse reinforcement\n",
      "learning” to try to recover the unknown\n",
      "reward function. We show that our algorithm\n",
      "terminates in a small number of iterations,\n",
      "and that even though we may never recover\n",
      "the expert’s reward function, the policy output\n",
      "by the algorithm will attain performance\n",
      "close to that of the expert, where here performance\n",
      "is measured with respect to the expert’s\n",
      "unknown reward function},\n",
      " author = {Abbeel, Pieter and Ng, Andrew Y},\n",
      " booktitle = {Proceedings of the twenty-first international conference on Machine learning},\n",
      " notes = {Empty},\n",
      " organization = {ACM},\n",
      " pages = {1},\n",
      " title = {Apprenticeship learning via inverse reinforcement learning},\n",
      " url = {#},\n",
      " year = {2004}\n",
      "}\n",
      "\n",
      "@misc{abbeel:irlslides,\n",
      " abstract = {},\n",
      " author = {Pieter Abbeel},\n",
      " notes = {some good references and notes for IRL stuff},\n",
      " title = {Inverse Reinforcement Learnign class slides},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{abbott2016focal,\n",
      " abstract = {The best examples of color terms across languages are often held to reflect universal focal colors in the opponent pairs red vs. green and yellow vs. blue. An opposing view holds that best examples reflect categories that are determined by local linguistic convention. We argue for a synthesis of these two proposals. We show that best examples of color terms across languages can be predicted from color term extensions using a statistical model that indicates which samples are most representative of a distribution. This model accounts for universal tendencies in best example choices across languages, and also accounts for cross-language variation. Our findings suggest that general statistical principles may illuminate fundamental aspects of color naming across languages.},\n",
      " author = {Abbott, Joshua T and Griffiths, Thomas L and Regier, Terry},\n",
      " journal = {Proceedings of the National Academy of Sciences},\n",
      " notes = {Empty},\n",
      " number = {40},\n",
      " pages = {11178--11183},\n",
      " publisher = {National Acad Sciences},\n",
      " title = {Focal colors across languages are representative members of color categories},\n",
      " url = {http://www.pnas.org/content/113/40/11178.short},\n",
      " volume = {113},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{akaike1974,\n",
      " abstract = {Empty},\n",
      " author = {Akaike, Hirotugu},\n",
      " journal = {Automatic Control, IEEE Transactions on},\n",
      " notes = {Empty},\n",
      " number = {6},\n",
      " pages = {716--723},\n",
      " publisher = {Ieee},\n",
      " title = {A new look at the statistical model identification},\n",
      " url = {#},\n",
      " volume = {19},\n",
      " year = {1974}\n",
      "}\n",
      "\n",
      "@article{Anderson1991,\n",
      " abstract = {Empty},\n",
      " author = {Anderson, John R.},\n",
      " journal = {Psychological Review},\n",
      " notes = {Empty},\n",
      " number = {3},\n",
      " pages = {409},\n",
      " publisher = {American Psychological Association},\n",
      " title = {The adaptive nature of human categorization.},\n",
      " url = {#},\n",
      " volume = {98},\n",
      " year = {1991}\n",
      "}\n",
      "\n",
      "@article{anderson1991adaptive,\n",
      " abstract = {Empty},\n",
      " author = {Anderson, John R},\n",
      " journal = {Psychological Review},\n",
      " notes = {Empty},\n",
      " number = {3},\n",
      " pages = {409},\n",
      " publisher = {American Psychological Association},\n",
      " title = {The adaptive nature of human categorization.},\n",
      " url = {#},\n",
      " volume = {98},\n",
      " year = {1991}\n",
      "}\n",
      "\n",
      "@inproceedings{andreas-klein:2014:W14-16,\n",
      " abstract = {Empty},\n",
      " address = {Ann Arbor, Michigan},\n",
      " author = {Andreas, Jacob  and  Klein, Dan},\n",
      " booktitle = {Proceedings of the Eighteenth Conference on Computational Natural Language Learning},\n",
      " month = {June},\n",
      " notes = {Empty},\n",
      " pages = {58--67},\n",
      " publisher = {Association for Computational Linguistics},\n",
      " title = {Grounding Language with Points and Paths in Continuous Spaces},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{andreas2016learning,\n",
      " abstract = {We describe a question answering model that applies to both images and structured knowledge bases. The model uses natural language strings to automatically assemble neural networks from a collection of composable modules. Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision. Our approach, which we term a dynamic neural model network, achieves state-of-the-art results on benchmark datasets in both visual and structured domains.},\n",
      " author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},\n",
      " journal = {arXiv preprint arXiv:1601.01705},\n",
      " notes = {Empty},\n",
      " title = {Learning to Compose Neural Networks for Question Answering},\n",
      " url = {#},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{AndreasRDK15,\n",
      " abstract = {Visual question answering is fundamentally compositional in nature---a question like \"where is the dog?\" shares substructure with questions like \"what color is the dog?\" and \"where is the cat?\" This paper seeks to simultaneously exploit the representational capacity of deep networks and the compositional linguistic structure of questions. We describe a procedure for constructing and learning *neural module networks*, which compose collections of jointly-trained neural \"modules\" into deep networks for question answering. Our approach decomposes questions into their linguistic substructures, and uses these structures to dynamically instantiate modular networks (with reusable components for recognizing dogs, classifying colors, etc.). The resulting compound networks are jointly trained. We evaluate our approach on two challenging datasets for visual question answering, achieving state-of-the-art results on both the VQA natural image dataset and a new dataset of complex questions about abstract shapes.},\n",
      " author = {Jacob Andreas and\n",
      "Marcus Rohrbach and\n",
      "Trevor Darrell and\n",
      "Dan Klein},\n",
      " bibsource = {dblp computer science bibliography, http://dblp.org},\n",
      " biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/AndreasRDK15},\n",
      " journal = {CoRR},\n",
      " notes = {Empty},\n",
      " timestamp = {Tue, 01 Dec 2015 19:22:34 +0100},\n",
      " title = {Deep Compositional Question Answering with Neural Module Networks},\n",
      " url = {#},\n",
      " volume = {abs/1511.02799},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@inproceedings{arisoy2012deep,\n",
      " abstract = {In recent years, neural network language models\n",
      "(NNLMs) have shown success in both\n",
      "peplexity and word error rate (WER) compared\n",
      "to conventional n-gram language models.\n",
      "Most NNLMs are trained with one hidden\n",
      "layer. Deep neural networks (DNNs) with\n",
      "more hidden layers have been shown to capture\n",
      "higher-level discriminative information\n",
      "about input features, and thus produce better\n",
      "networks. Motivated by the success of DNNs\n",
      "in acoustic modeling, we explore deep neural\n",
      "network language models (DNN LMs) in this\n",
      "paper. Results on a Wall Street Journal (WSJ)\n",
      "task demonstrate that DNN LMs offer improvements\n",
      "over a single hidden layer NNLM.\n",
      "Furthermore, our preliminary results are competitive\n",
      "with a model M language model, considered\n",
      "to be one of the current state-of-the-art\n",
      "techniques for language modeling.},\n",
      " author = {Arisoy, Ebru and Sainath, Tara N and Kingsbury, Brian and Ramabhadran, Bhuvana},\n",
      " booktitle = {Proceedings of the NAACL-HLT 2012 Workshop: Will We Ever Really Replace the N-gram Model? On the Future of Language Modeling for HLT},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {20--28},\n",
      " title = {Deep neural network language models},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{BahdanauCB14,\n",
      " abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},\n",
      " author = {Dzmitry Bahdanau and\n",
      "Kyunghyun Cho and\n",
      "Yoshua Bengio},\n",
      " bibsource = {dblp computer science bibliography, http://dblp.org},\n",
      " biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/BahdanauCB14},\n",
      " journal = {CoRR},\n",
      " notes = {Empty},\n",
      " timestamp = {Wed, 01 Oct 2014 15:00:04 +0200},\n",
      " title = {Neural Machine Translation by Jointly Learning to Align and Translate},\n",
      " url = {#},\n",
      " volume = {abs/1409.0473},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{barker2002dynamics,\n",
      " abstract = {Empty},\n",
      " author = {Barker, Chris},\n",
      " journal = {Linguistics and Philosophy},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {1--36},\n",
      " publisher = {Springer},\n",
      " title = {The dynamics of vagueness},\n",
      " url = {#},\n",
      " volume = {25},\n",
      " year = {2002}\n",
      "}\n",
      "\n",
      "@article{barker:lp02,\n",
      " abstract = {Empty},\n",
      " author = {Chris Barker},\n",
      " journal = {Linguistics and Philosophy},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {1--36},\n",
      " title = {The Dynamics of Vagueness},\n",
      " url = {#},\n",
      " volume = {25},\n",
      " year = {2002}\n",
      "}\n",
      "\n",
      "@inproceedings{baumgaertner2012towards,\n",
      " abstract = {Empty},\n",
      " author = {Baumgaertner, Bert and Fernández, Raquel and Stone, Matthew},\n",
      " booktitle = {Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {80--84},\n",
      " summary = {This paper describes experiments with generation and interpretation of color terms. The first experiment showed only a color and participants were asked to generate a color label. There were two conditions that were varied. First, basic and non basic color stimuli. Second, distractor and no distractors. Basic colors showed an overwelming majority chose to label the color a single label (in the no distractor case) or very few labels (in the distractor case). Non basic colors showed greater variation in the generation labels for both the no-distractor and distractor conditions. The second experiment presented a set of color stimuli and color word; participants were asked to choose the correct object. For the basic color term, this had a near perfect success rate. For the non-basic color terms, the success rate was high for no competitors, but dropped to 78% with competitors},\n",
      " title = {Towards a flexible semantics: colour terms in collaborative reference tasks},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{beltagy2013montague,\n",
      " abstract = {Empty},\n",
      " author = {Beltagy, Islam and Chau, Cuong and Boleda, Gemma and Garrette, Dan and Erk, Katrin and Mooney, Raymond},\n",
      " journal = {Proceedings of* SEM},\n",
      " notes = {Empty},\n",
      " pages = {11--21},\n",
      " title = {Montague meets markov: Deep semantics with probabilistic logical form},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@incollection{bengio2006neural,\n",
      " abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of\n",
      "words in a language. This is intrinsically difficult because of the curse of dimensionality: a word\n",
      "sequence on which the model will be tested is likely to be different from all the word sequences seen\n",
      "during training. Traditional but very successful approaches based on n-grams obtain generalization\n",
      "by concatenating very short overlapping sequences seen in the training set. We propose to fight the\n",
      "curse of dimensionality by learning a distributed representation for words which allows each\n",
      "training sentence to inform the model about an exponential number of semantically neighboring\n",
      "sentences. The model learns simultaneously (1) a distributed representation for each word along\n",
      "with (2) the probability function for word sequences, expressed in terms of these representations.\n",
      "Generalization is obtained because a sequence of words that has never been seen before gets high\n",
      "probability if it is made of words that are similar (in the sense of having a nearby representation) to\n",
      "words forming an already seen sentence. Training such large models (with millions of parameters)\n",
      "within a reasonable time is itself a significant challenge. We report on experiments using neural\n",
      "networks for the probability function, showing on two text corpora that the proposed approach\n",
      "significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to\n",
      "take advantage of longer contexts.},\n",
      " author = {Bengio, Yoshua and Schwenk, Holger and Senécal, Jean-Sébastien and Morin, Fréderic and Gauvain, Jean-Luc},\n",
      " booktitle = {Innovations in Machine Learning},\n",
      " notes = {Empty},\n",
      " pages = {137--186},\n",
      " publisher = {Springer},\n",
      " title = {Neural probabilistic language models},\n",
      " url = {#},\n",
      " year = {2006}\n",
      "}\n",
      "\n",
      "@book{Bengio2009,\n",
      " abstract = {Empty},\n",
      " author = {Bengio, Yoshua},\n",
      " booktitle = {Foundations and Trends® in Machine Learning},\n",
      " doi = {10.1561/2200000006},\n",
      " file = {:C$\\backslash$:/research/papers/deep networks/learning-deep-ai.pdf:pdf},\n",
      " isbn = {2200000006},\n",
      " issn = {1935-8237},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {1--127},\n",
      " title = {{Learning Deep Architectures for AI}},\n",
      " url = {#},\n",
      " volume = {2},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@book{berlin1969basic,\n",
      " abstract = {Empty},\n",
      " author = {Berlin, Brent and Kay, Paul},\n",
      " notes = {Empty},\n",
      " title = {Basic color terms},\n",
      " url = {#},\n",
      " year = {1969}\n",
      "}\n",
      "\n",
      "@book{Berlin1991,\n",
      " abstract = {Empty},\n",
      " author = {Berlin, Brent},\n",
      " notes = {Empty},\n",
      " publisher = {University of California Press},\n",
      " title = {Basic color terms: Their universality and evolution},\n",
      " url = {#},\n",
      " year = {1991}\n",
      "}\n",
      "\n",
      "@inproceedings{bhatnagar2007incremental,\n",
      " abstract = {We present four new reinforcement learning algorithms based on actor-critic and\n",
      "natural-gradient ideas, and provide their convergence proofs. Actor-critic reinforcement\n",
      "learning methods are online approximations to policy iteration in which\n",
      "the value-function parameters are estimated using temporal difference learning\n",
      "and the policy parameters are updated by stochastic gradient descent. Methods\n",
      "based on policy gradients in this way are of special interest because of their compatibility\n",
      "with function approximation methods, which are needed to handle large\n",
      "or infinite state spaces. The use of temporal difference learning in this way is of\n",
      "interest because in many applications it dramatically reduces the variance of the\n",
      "gradient estimates. The use of the natural gradient is of interest because it can\n",
      "produce better conditioned parameterizations and has been shown to further reduce\n",
      "variance in some cases. Our results extend prior two-timescale convergence\n",
      "results for actor-critic methods by Konda and Tsitsiklis by using temporal difference\n",
      "learning in the actor and by incorporating natural gradients, and they extend\n",
      "prior empirical studies of natural actor-critic methods by Peters, Vijayakumar and\n",
      "Schaal by providing the first convergence proofs and the first fully incremental\n",
      "algorithms.},\n",
      " author = {Bhatnagar, Shalabh and Ghavamzadeh, Mohammad and Lee, Mark and Sutton, Richard S},\n",
      " booktitle = {Advances in neural information processing systems},\n",
      " notes = {Empty},\n",
      " pages = {105--112},\n",
      " title = {Incremental natural actor-critic algorithms},\n",
      " url = {#},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{Bo2010,\n",
      " abstract = {Empty},\n",
      " author = {Bo, Liefeng and Ren, X and Fox, Dieter},\n",
      " file = {:C$\\backslash$:/research/papers/computer vision/bo_nips10.pdf:pdf},\n",
      " journal = {NIPS},\n",
      " notes = {Empty},\n",
      " pages = {1--9},\n",
      " title = {{Kernel Descriptors for Visual Recognition.}},\n",
      " url = {#},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@article{Bo2013,\n",
      " abstract = {Empty},\n",
      " author = {Bo, Liefeng and Fox, Dieter},\n",
      " doi = {10.1109/ICRA.2013.6630858},\n",
      " isbn = {978-1-4673-5643-5},\n",
      " journal = {2013 IEEE International Conference on Robotics and Automation},\n",
      " month = {May},\n",
      " notes = {Empty},\n",
      " pages = {2096--2103},\n",
      " publisher = {Ieee},\n",
      " title = {{Attribute based object identification}},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@inproceedings{boularias2011relative,\n",
      " abstract = {We consider the problem of imitation learning\n",
      "where the examples, demonstrated by an\n",
      "expert, cover only a small part of a large\n",
      "state space. Inverse Reinforcement Learning\n",
      "(IRL) provides an efficient tool for generalizing\n",
      "the demonstration, based on the assumption\n",
      "that the expert is optimally acting in\n",
      "a Markov Decision Process (MDP). Most of\n",
      "the past work on IRL requires that a (near)-\n",
      "optimal policy can be computed for different\n",
      "reward functions. However, this requirement\n",
      "can hardly be satisfied in systems with\n",
      "a large, or continuous, state space. In this paper,\n",
      "we propose a model-free IRL algorithm,\n",
      "where the relative entropy between the empirical\n",
      "distribution of the state-action trajectories\n",
      "under a baseline policy and their distribution\n",
      "under the learned policy is minimized\n",
      "by stochastic gradient descent. We compare\n",
      "this new approach to well-known IRL algorithms\n",
      "using learned MDP models. Empirical\n",
      "results on simulated car racing, gridworld\n",
      "and ball-in-a-cup problems show that our approach\n",
      "is able to learn good policies from a\n",
      "small number of demonstrations.},\n",
      " author = {Boularias, Abdeslam and Kober, Jens and Peters, Jan R},\n",
      " booktitle = {International Conference on Artificial Intelligence and Statistics},\n",
      " notes = {Empty},\n",
      " pages = {182--189},\n",
      " title = {Relative entropy inverse reinforcement learning},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{bowman2015recursive,\n",
      " abstract = {Empty},\n",
      " author = {Bowman, Samuel R and Potts, Christopher and Manning, Christopher D},\n",
      " journal = {ACL-IJCNLP 2015},\n",
      " notes = {Empty},\n",
      " pages = {12},\n",
      " title = {Recursive neural networks can learn logical semantics},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@article{brennan/clark:pacts,\n",
      " abstract = {Empty},\n",
      " author = {Susan E. Brennan and Herbert H. Clark},\n",
      " journal = {Journal of Experimental Psychology: Learning, Memory\n",
      "and Cognition},\n",
      " notes = {Empty},\n",
      " number = {6},\n",
      " pages = {1482--1493},\n",
      " title = {Conceptual pacts and lexical choice in conversation},\n",
      " url = {#},\n",
      " volume = {22},\n",
      " year = {1996}\n",
      "}\n",
      "\n",
      "@article{brooks1998general,\n",
      " abstract = {Empty},\n",
      " author = {Brooks, Stephen P and Gelman, Andrew},\n",
      " journal = {Journal of computational and graphical statistics},\n",
      " notes = {Empty},\n",
      " number = {4},\n",
      " pages = {434--455},\n",
      " publisher = {Taylor & Francis},\n",
      " title = {General methods for monitoring convergence of iterative simulations},\n",
      " url = {#},\n",
      " volume = {7},\n",
      " year = {1998}\n",
      "}\n",
      "\n",
      "@article{brown1992estimate,\n",
      " abstract = {Empty},\n",
      " author = {Brown, Peter F. and Pietra, Vincent J. Della and Mercer, Robert L. and Pietra, Stephen A. Della and Lai, Jennifer C.},\n",
      " journal = {Computational Linguistics},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {31--40},\n",
      " publisher = {MIT Press},\n",
      " title = {An estimate of an upper bound for the entropy of English},\n",
      " url = {#},\n",
      " volume = {18},\n",
      " year = {1992}\n",
      "}\n",
      "\n",
      "@article{Bruni2012,\n",
      " abstract = {Empty},\n",
      " author = {Bruni, Elia and Boleda, Gemma and Baroni, Marco and Tran, Nam-Khanh},\n",
      " booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {136--145},\n",
      " title = {Distributional semantics in technicolor},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{budescu1987subjective,\n",
      " abstract = {Empty},\n",
      " author = {Budescu, David V and Wallsten, Thomas S},\n",
      " notes = {Empty},\n",
      " publisher = {John Wiley & Sons},\n",
      " title = {Subjective estimation of precise and vague uncertainties.},\n",
      " url = {#},\n",
      " year = {1987}\n",
      "}\n",
      "\n",
      "@article{budescu1988decisions,\n",
      " abstract = {Empty},\n",
      " author = {Budescu, David V and Weinberg, Shalva and Wallsten, Thomas S},\n",
      " journal = {Journal of Experimental Psychology: Human Perception and Performance},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {281},\n",
      " publisher = {American Psychological Association},\n",
      " title = {Decisions based on numerically and verbally expressed uncertainties.},\n",
      " url = {#},\n",
      " volume = {14},\n",
      " year = {1988}\n",
      "}\n",
      "\n",
      "@article{chamorrofuzzy,\n",
      " abstract = {In this paper we introduce formal definitions of the concepts of fuzzy color and fuzzy color space. First, we formalize the notion of fuzzy color for representing the correspondence between computational representation of colors, and perceptual color categories identified by a color name. Second, we propose a methodology for learning fuzzy colors based on the paradigm of conceptual spaces, where prototypes are used for each category to be learnt. Since the conceptual space approach yields crisp categorisations, we introduce a novel methodology for defining fuzzy boundaries of color categories on the basis of a Voronoi tessellation of a color space. Finally, we also formalize the notion of fuzzy color space as the collection of fuzzy colors corresponding to the color categories employed in a certain context/application and/or for an specific user. Different typologies of fuzzy color spaces are proposed in order to be consistent with the nature of the categories we want to model. Our approach is illustrated by defining fuzzy color spaces using RGB with the Euclidean distance. Examples based on the wellknown ISCC-NBS color naming system are presented, as well as others based on collections of color names and prototypes provided by users. The proposal is evaluated and compared with the most used approaches for color modeling. Additionally, a website including all experimentation data, software implementing our models, and additional materials, is available to researchers in color modeling.},\n",
      " author = {Chamorro, Jesus and Soto-Hidalgo, Jose Manuel and Martinez-Jimenez, Pedro Manuel and Sanchez, D},\n",
      " journal = {IEEE Transactions on Fuzzy Systems},\n",
      " notes = {Empty},\n",
      " publisher = {IEEE},\n",
      " title = {Fuzzy Color Spaces: A Conceptual Approach to Color Vision},\n",
      " url = {http://ieeexplore.ieee.org/abstract/document/7572922/?reload=true},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@book{chater2003rational,\n",
      " abstract = {Empty},\n",
      " author = {Chater, Nick and Oaksford, Mike},\n",
      " notes = {Empty},\n",
      " publisher = {Wiley Online Library},\n",
      " title = {Rational models of cognition},\n",
      " url = {#},\n",
      " year = {2003}\n",
      "}\n",
      "\n",
      "@inproceedings{chen1996empirical,\n",
      " abstract = {Empty},\n",
      " author = {Chen, Stanley F and Goodman, Joshua},\n",
      " booktitle = {Proceedings of the 34th annual meeting on Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {310--318},\n",
      " title = {An empirical study of smoothing techniques for language modeling},\n",
      " url = {#},\n",
      " year = {1996}\n",
      "}\n",
      "\n",
      "@inproceedings{Chen2008,\n",
      " abstract = {We present a novel commentator system that learns language from sportscasts$\\backslash$nof simulated soccer games. The system learns to parse and generate$\\backslash$ncommentaries without any engineered knowledge about the English language.$\\backslash$nTraining is done using only ambiguous supervision in the form of$\\backslash$ntextual human commentaries and simulation states of the soccer games.$\\backslash$nThe system simultaneously tries to establish correspondences between$\\backslash$nthe commentaries and the simulation states as well as build a translation$\\backslash$nmodel. We also present a novel algorithm, Iterative Generation Strategy$\\backslash$nLearning (IGSL), for deciding which events to comment on. Human evaluations$\\backslash$nof the generated commentaries indicate they are of reasonable quality$\\backslash$ncompared to human commentaries.},\n",
      " author = {Chen, David L and Mooney, Raymond J},\n",
      " booktitle = {ICML '08: Proceedings of the 25th international conference on Machine learning},\n",
      " doi = {http://doi.acm.org/10.1145/1390156.1390173},\n",
      " isbn = {978-1-60558-205-4},\n",
      " notes = {Empty},\n",
      " pages = {128--135},\n",
      " title = {{Learning to sportscast: a test of grounded language acquisition}},\n",
      " url = {#},\n",
      " year = {2008}\n",
      "}\n",
      "\n",
      "@article{cheung2014discovering,\n",
      " abstract = {Empty},\n",
      " author = {Cheung, Brian and Livezey, Jesse A and Bansal, Arjun K and Olshausen, Bruno A},\n",
      " journal = {arXiv preprint arXiv:1412.6583},\n",
      " notes = {Empty},\n",
      " title = {Discovering Hidden Factors of Variation in Deep Networks},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@inproceedings{chiang2000statistical,\n",
      " abstract = {Empty},\n",
      " author = {Chiang, David},\n",
      " booktitle = {Proceedings of the 38th Annual Meeting on Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {456--463},\n",
      " title = {Statistical parsing with an automatically-extracted tree adjoining grammar},\n",
      " url = {#},\n",
      " year = {2000}\n",
      "}\n",
      "\n",
      "@article{chib1995understanding,\n",
      " abstract = {Empty},\n",
      " author = {Chib, Siddhartha and Greenberg, Edward},\n",
      " journal = {The American Statistician},\n",
      " notes = {Empty},\n",
      " number = {4},\n",
      " pages = {327--335},\n",
      " publisher = {Taylor & Francis Group},\n",
      " title = {Understanding the metropolis-hastings algorithm},\n",
      " url = {#},\n",
      " volume = {49},\n",
      " year = {1995}\n",
      "}\n",
      "\n",
      "@article{choi2011inverse,\n",
      " abstract = {Inverse reinforcement learning (IRL) is the problem of recovering the underlying reward function\n",
      "from the behavior of an expert. Most of the existing IRL algorithms assume that the environment is\n",
      "modeled as a Markov decision process (MDP), although it is desirable to handle partially observable\n",
      "settings in order to handle more realistic scenarios. In this paper, we present IRL algorithms for\n",
      "partially observable environments that can be modeled as a partially observable Markov decision\n",
      "process (POMDP). We deal with two cases according to the representation of the given expert’s\n",
      "behavior, namely the case in which the expert’s policy is explicitly given, and the case in which the\n",
      "expert’s trajectories are available instead. The IRL in POMDPs poses a greater challenge than in\n",
      "MDPs since it is not only ill-posed due to the nature of IRL, but also computationally intractable\n",
      "due to the hardness in solving POMDPs. To overcome these obstacles, we present algorithms that\n",
      "exploit some of the classical results from the POMDP literature. Experimental results on several\n",
      "benchmark POMDP domains show that our work is useful for partially observable settings},\n",
      " author = {Choi, Jaedeug and Kim, Kee-Eung},\n",
      " journal = {The Journal of Machine Learning Research},\n",
      " notes = {Empty},\n",
      " pages = {691--730},\n",
      " publisher = {JMLR. org},\n",
      " title = {Inverse reinforcement learning in partially observable environments},\n",
      " url = {#},\n",
      " volume = {12},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{clark/wilkes:collaborating,\n",
      " abstract = {Empty},\n",
      " author = {H. H. Clark and D. Wilkes-Gibbs},\n",
      " journal = {Cognition},\n",
      " notes = {Empty},\n",
      " pages = {1--39},\n",
      " title = {Referring as a collaborative process},\n",
      " url = {#},\n",
      " volume = {22},\n",
      " year = {1986}\n",
      "}\n",
      "\n",
      "@book{clark1996using,\n",
      " abstract = {Empty},\n",
      " author = {Clark, Herbert H},\n",
      " notes = {Empty},\n",
      " publisher = {Cambridge university press},\n",
      " title = {Using language},\n",
      " url = {#},\n",
      " year = {1996}\n",
      "}\n",
      "\n",
      "@inproceedings{cohn2009inducing,\n",
      " abstract = {Empty},\n",
      " author = {Cohn, Trevor and Goldwater, Sharon and Blunsom, Phil},\n",
      " booktitle = {Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {548--556},\n",
      " title = {Inducing compact but accurate tree-substitution grammars},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@inproceedings{collins1997three,\n",
      " abstract = {Empty},\n",
      " author = {Collins, Michael},\n",
      " booktitle = {Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {16--23},\n",
      " title = {Three generative, lexicalised models for statistical parsing},\n",
      " url = {#},\n",
      " year = {1997}\n",
      "}\n",
      "\n",
      "@article{Cotton1995,\n",
      " abstract = {Empty},\n",
      " author = {Cotton, Symon D'O},\n",
      " journal = {University of Birmingham, School of Computer Science e-print, 1st May},\n",
      " notes = {Empty},\n",
      " publisher = {Citeseer},\n",
      " title = {Colour, colour spaces and the human visual system},\n",
      " url = {#},\n",
      " year = {1995}\n",
      "}\n",
      "\n",
      "@article{cumming:2013,\n",
      " abstract = {Empty},\n",
      " author = {Sam Cumming},\n",
      " journal = {Philosophers' Imprint},\n",
      " notes = {Empty},\n",
      " number = {4},\n",
      " pages = {1--16},\n",
      " title = {Coordination and content},\n",
      " url = {#},\n",
      " volume = {13},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{Dalal2005,\n",
      " abstract = {Empty},\n",
      " author = {Dalal, N. and Triggs, B.},\n",
      " doi = {10.1109/CVPR.2005.177},\n",
      " journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},\n",
      " notes = {Empty},\n",
      " pages = {886--893},\n",
      " publisher = {Ieee},\n",
      " title = {{Histograms of Oriented Gradients for Human Detection}},\n",
      " url = {#},\n",
      " volume = {1},\n",
      " year = {2005}\n",
      "}\n",
      "\n",
      "@article{daume2009search,\n",
      " abstract = {Empty},\n",
      " author = {{Daumé III}, Hal and Langford, John and Marcu, Daniel},\n",
      " journal = {Machine learning},\n",
      " notes = {Empty},\n",
      " number = {3},\n",
      " pages = {297--325},\n",
      " publisher = {Springer},\n",
      " title = {Search-based structured prediction},\n",
      " url = {#},\n",
      " volume = {75},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@misc{davidsilver:rllecture7,\n",
      " abstract = {Empty},\n",
      " author = {David Silver},\n",
      " notes = {Empty},\n",
      " title = {Lecture 7: Policy Gradient Methods (youtube)},\n",
      " url = {#},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@misc{davidsilver:rllecture7slides,\n",
      " abstract = {Empty},\n",
      " author = {David Silver},\n",
      " notes = {Empty},\n",
      " title = {Lecture 7: Policy Gradient Methods (slides)},\n",
      " url = {#},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@inproceedings{dawson2013generative,\n",
      " abstract = {Empty},\n",
      " author = {Dawson, Colin R and Wright, Jeremy and Rebguns, Antons and\n",
      "Escárcega, Marco Valenzuela and Fried, Daniel and Cohen, Paul R},\n",
      " booktitle = {Development and Learning and Epigenetic Robotics (ICDL),\n",
      "2013 IEEE Third Joint International Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {1--8},\n",
      " title = {A generative probabilistic framework for learning spatial\n",
      "language},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@phdthesis{deepakramachandran:thesis,\n",
      " abstract = {The field of Reinforcement Learning is concerned with teaching agents to take optimal\n",
      "decisions to maximize their total utility in complicated environments. A Reinforcement\n",
      "Learning problem, generally described by the Markov Decision Process\n",
      "formalism, has several complex interacting components, unlike in other machine\n",
      "learning settings. I distinguish three: the state-space/ transition model, the\n",
      "reward function, and the observation model. In this thesis, I present a framework\n",
      "for studying how the state of knowledge or uncertainty of each component affects\n",
      "the Reinforcement Learning process. I focus on the reward function and the observation\n",
      "model, which has traditionally received little attention. Algorithms for\n",
      "learning good policies when these components are completely specified are well\n",
      "understood. However, it is less clear what to do when they are unknown, uncertain\n",
      "or irrelevant. In this thesis, I describe how to adapt Reinforcement Learning\n",
      "algorithms to cope with these situations.\n",
      "Recently there has been great interest in the Inverse Reinforcement Learning\n",
      "problem where the objective is to learn the reward function from evidence of an\n",
      "agent’s reward-maximizing policy. The usual goal is to perform apprenticeship\n",
      "learning where the agent learns the optimal action to perform from an expert.\n",
      "However, sometimes the reward function is of independent interest as well. I\n",
      "describe a Bayesian Inverse Reinforcement Learning approach to this problem.\n",
      "BIRL uses a generative model to describe the decision-making process and by\n",
      "inverting it we can infer the reward function from action observations. It is distinguished\n",
      "from other IRL approaches by placing emphasis on the accuracy of the\n",
      "reward function in itself, and not just as an intermediate step to apprenticeship\n",
      "learning. BIRL is also able to handle incomplete and contradictory information\n",
      "from the expert. It has been applied successfully to preference elicitation problem\n",
      "for computer games and robot manipulation. In a recent comparison of IRL\n",
      "approaches, BIRL was the best-performing general IRL algorithm.\n",
      "I also extend this model to do a related task, Reward Shaping. In reward\n",
      "ii\n",
      "shaping, we seek to adjust a known reward function to make the learning agent\n",
      "converge on the optimal policy as fast as possible. Reward shaping has been\n",
      "proposed and studied previously in many applications, typically using additive\n",
      "potential functions. However the requirement of absolute policy-invariance is too\n",
      "strict to admit many useful cases of shaping. I define Bayesian Reward Shaping,\n",
      "which is a generalization to a soft form of reward shaping, and provide algorithms\n",
      "for achieving it.\n",
      "The impact of observation models on reinforcement learning has been studied\n",
      "even less than reward functions. This is surpising, considering how adding partial\n",
      "observability to an MDP model blows up the computational complexity and hence\n",
      "a better understanding of the tradeoffs between representational accuracy and ef-\n",
      "ficiency would be helpful. In this work, I describe how in certain cases POMDPs\n",
      "can be approximated by MDPs or slightly more complicated models with bounded\n",
      "performance loss. I also present an algorithm, called Smoothed Q-Learning for\n",
      "learning policies when the observation models are uncertain. Smoothed Sarsa is\n",
      "based on the idea that in many real-world POMDPs better state estimates can\n",
      "be made at later time steps and thus delaying the backup step of a temporal\n",
      "difference-based algorithm can shortcut the uncertainty in the obervation model\n",
      "and approximate the underlying MDP better.\n",
      "Combining these approaches together (Bayesian Reward Shaping and Smoothed\n",
      "Sarsa), a mobile robot was trained to execute delivery tasks in an office environment.},\n",
      " author = {Deepak Ramachandran},\n",
      " notes = {Empty},\n",
      " school = {University of Illinois at Urbana-Champaign},\n",
      " title = {Knowledge and Ignorance in Reinforcement Learning},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@inproceedings{DeVault2004interpreting,\n",
      " abstract = {Empty},\n",
      " author = {DeVault, David and Stone, Matthew},\n",
      " booktitle = {Proceedings of the 20th international conference on Computational Linguistics},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {1247},\n",
      " title = {Interpreting vague utterances in context},\n",
      " url = {#},\n",
      " year = {2004}\n",
      "}\n",
      "\n",
      "@inproceedings{DeVault2006,\n",
      " abstract = {Empty},\n",
      " author = {DeVault, David and Oved, Iris and Stone, Matthew},\n",
      " booktitle = {Proceedings of the National Conference on Artificial Intelligence},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " organization = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},\n",
      " pages = {747},\n",
      " title = {Societal grounding is essential to meaningful language use},\n",
      " url = {#},\n",
      " volume = {21},\n",
      " year = {2006}\n",
      "}\n",
      "\n",
      "@article{DiCarlo2007333,\n",
      " abstract = {Empty},\n",
      " author = {James J. DiCarlo and David D. Cox},\n",
      " doi = {http://dx.doi.org/10.1016/j.tics.2007.06.010},\n",
      " issn = {1364-6613},\n",
      " journal = {Trends in Cognitive Sciences },\n",
      " note = {},\n",
      " notes = {Empty},\n",
      " number = {8},\n",
      " pages = {333 - 341},\n",
      " title = {Untangling invariant object recognition },\n",
      " url = {#},\n",
      " volume = {11},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{dong2016language,\n",
      " abstract = {Semantic parsing aims at mapping natural language to machine interpretable meaning representations. Traditional approaches rely on high-quality lexicons, manually-built templates, and linguistic features which are either domain- or representation-specific. In this paper, we present a general method based on an attention-enhanced sequence-to-sequence model. We encode input sentences into vector representations using recurrent neural networks, and generate their logical forms by conditioning the output on the encoding vectors. The model is trained in an end-to-end fashion to maximize the likelihood of target logical forms given the natural language inputs. Experimental results on four datasets show that our approach performs competitively without using hand-engineered features and is easy to adapt across domains and meaning representations.},\n",
      " author = {Dong, Li and Lapata, Mirella},\n",
      " journal = {arXiv preprint arXiv:1601.01280},\n",
      " notes = {Empty},\n",
      " title = {Language to Logical Form with Neural Attention},\n",
      " url = {#},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{eigenvsfisherfaces1997,\n",
      " abstract = {Empty},\n",
      " author = {Belhumeur, Peter N and Hespanha, João P and Kriegman, David J},\n",
      " journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},\n",
      " notes = {Empty},\n",
      " number = {7},\n",
      " pages = {711--720},\n",
      " publisher = {IEEE},\n",
      " title = {Eigenfaces vs. fisherfaces: Recognition using class specific linear projection},\n",
      " url = {#},\n",
      " volume = {19},\n",
      " year = {1997}\n",
      "}\n",
      "\n",
      "@article{Everingham10,\n",
      " abstract = {Empty},\n",
      " author = {Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.},\n",
      " journal = {International Journal of Computer Vision},\n",
      " month = {June},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {303--338},\n",
      " title = {The Pascal Visual Object Classes (VOC) Challenge},\n",
      " url = {#},\n",
      " volume = {88},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@book{fairchild2013color,\n",
      " abstract = {Empty},\n",
      " author = {Fairchild, Mark D.},\n",
      " isbn = {9781118653104},\n",
      " lccn = {2013017473},\n",
      " notes = {Empty},\n",
      " publisher = {Wiley},\n",
      " series = {The Wiley-IS&T Series in Imaging Science and Technology},\n",
      " title = {Color Appearance Models},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{Farhadi2009,\n",
      " abstract = {Empty},\n",
      " author = {Farhadi, Ali and Endres, Ian and Hoiem, Derek and Forsyth, David},\n",
      " doi = {10.1109/CVPR.2009.5206772},\n",
      " isbn = {978-1-4244-3992-8},\n",
      " journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},\n",
      " month = {June},\n",
      " notes = {Farhadi seeks to learn generalizable properties across object categories.  In order to learn a \"has wheels\" classifier, this requires factoring out correlated attributes like \"metallic\".   They do this by using an L1 regularizer on within class sensitivity (e.g. cars with wheels vs cars without wheels). },\n",
      " pages = {1778--1785},\n",
      " publisher = {Ieee},\n",
      " title = {{Describing objects by their attributes}},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@online{FarhadiWebsite,\n",
      " abstract = {Empty},\n",
      " author = {Farhadi, Ali and Endres, Ian and Hoiem, Derek and Forsyth, David},\n",
      " notes = {Empty},\n",
      " title = {Describing Objects by Their Attributes},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@article{Feldman2003,\n",
      " abstract = {Empty},\n",
      " author = {Feldman, Jacob},\n",
      " journal = {Journal of Mathematical Psychology},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {75--89},\n",
      " publisher = {Elsevier},\n",
      " title = {A catalog of Boolean concepts},\n",
      " url = {#},\n",
      " volume = {47},\n",
      " year = {2003}\n",
      "}\n",
      "\n",
      "@misc{feldman2012perceptual,\n",
      " abstract = {Empty},\n",
      " author = {Feldman, Jacob and Singh, Manish and Froyen, Vicky},\n",
      " notes = {Empty},\n",
      " publisher = {Gepshtein S. Maloney L. Singh M.(Eds.) Oxford handbook of computational perceptual organization. Oxford, UK: Oxford University Press},\n",
      " title = {Perceptual grouping as Bayesian mixture estimation},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@inproceedings{Felzenszwalb2008,\n",
      " abstract = {Empty},\n",
      " author = {Felzenszwalb, Pedro and McAllester, David and Ramanan, Deva},\n",
      " booktitle = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},\n",
      " file = {:C$\\backslash$:/research/papers/computer vision/felzenszwalb_deforable_parts_cvpr.pdf:pdf},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {1--8},\n",
      " title = {A discriminatively trained, multiscale, deformable part model},\n",
      " url = {#},\n",
      " year = {2008}\n",
      "}\n",
      "\n",
      "@article{fillenbaum1991some,\n",
      " abstract = {Empty},\n",
      " author = {Fillenbaum, Samuel and Wallsten, Thomas S and Cohen, Brent L and Cox, James A},\n",
      " journal = {The American Journal of Psychology},\n",
      " notes = {Empty},\n",
      " pages = {35--60},\n",
      " publisher = {JSTOR},\n",
      " title = {Some effects of vocabulary and communication task on the understanding and use of vague probability expressions},\n",
      " url = {#},\n",
      " year = {1991}\n",
      "}\n",
      "\n",
      "@article{Foster2011,\n",
      " abstract = {A quarter of a century ago, the first systematic behavioral experiments were performed to clarify the nature of color constancy-the effect whereby the perceived color of a surface remains constant despite changes in the spectrum of the illumination. At about the same time, new models of color constancy appeared, along with physiological data on cortical mechanisms and photographic colorimetric measurements of natural scenes. Since then, as this review shows, there have been many advances. The theoretical requirements for constancy have been better delineated and the range of experimental techniques has been greatly expanded; novel invariant properties of images and a variety of neural mechanisms have been identified; and increasing recognition has been given to the relevance of natural surfaces and scenes as laboratory stimuli. Even so, there remain many theoretical and experimental challenges, not least to develop an account of color constancy that goes beyond deterministic and relatively simple laboratory stimuli and instead deals with the intrinsically variable nature of surfaces and illuminations present in the natural world.},\n",
      " author = {Foster, David H},\n",
      " doi = {10.1016/j.visres.2010.09.006},\n",
      " file = {:C$\\backslash$:/research/papers/computer vision/Foster_color_constancy.pdf:pdf},\n",
      " issn = {1878-5646},\n",
      " journal = {Vision research},\n",
      " keywords = {Bayes Theorem,Color Perception,Color Perception: physiology,Humans,Lighting,Linear Models,Nature,Psychophysics},\n",
      " month = {April},\n",
      " notes = {Empty},\n",
      " number = {7},\n",
      " pages = {674--700},\n",
      " pmid = {20849875},\n",
      " title = {{Color constancy.}},\n",
      " url = {#},\n",
      " volume = {51},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{foster:2011,\n",
      " abstract = {Empty},\n",
      " author = {David H. Foster},\n",
      " journal = {Vision Research},\n",
      " notes = {Empty},\n",
      " number = {7},\n",
      " pages = {674--700},\n",
      " title = {Color constancy},\n",
      " url = {#},\n",
      " volume = {51},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{frank2012predicting,\n",
      " abstract = {Empty},\n",
      " author = {Frank, Michael C and Goodman, Noah D},\n",
      " journal = {Science},\n",
      " notes = {Empty},\n",
      " number = {6084},\n",
      " pages = {998--998},\n",
      " publisher = {American Association for the Advancement of Science},\n",
      " title = {Predicting pragmatic reasoning in language games},\n",
      " url = {#},\n",
      " volume = {336},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@incollection{frank:nips07,\n",
      " abstract = {Empty},\n",
      " address = {Cambridge, MA},\n",
      " author = {Michael Frank and Noah Goodman and Joshua Tenenbaum},\n",
      " booktitle = {Advances in Neural Information Processing Systems 20},\n",
      " editor = {J.C. Platt and D. Koller and Y. Singer and S. Roweis},\n",
      " notes = {Empty},\n",
      " pages = {457--464},\n",
      " publisher = {MIT Press},\n",
      " title = {A {B}ayesian Framework for Cross-Situational Word-Learning},\n",
      " url = {#},\n",
      " year = {2008}\n",
      "}\n",
      "\n",
      "@article{franke2016reasoning,\n",
      " abstract = {Empty},\n",
      " author = {Franke, Michael and Degen, Judith},\n",
      " journal = {PloS one},\n",
      " notes = {Empty},\n",
      " number = {5},\n",
      " pages = {e0154854},\n",
      " publisher = {Public Library of Science},\n",
      " title = {Reasoning in reference games: Individual-vs. population-level probabilistic modeling},\n",
      " url = {#},\n",
      " volume = {11},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@inproceedings{frome2013devise,\n",
      " abstract = {Empty},\n",
      " author = {Frome, Andrea and Corrado, Greg S and Shlens, Jon and Bengio, Samy and Dean, Jeff and Mikolov, Tomas and others},\n",
      " booktitle = {Advances in Neural Information Processing Systems},\n",
      " notes = {Empty},\n",
      " pages = {2121--2129},\n",
      " title = {Devise: A deep visual-semantic embedding model},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@phdthesis{froyen2014bayesian,\n",
      " abstract = {Empty},\n",
      " author = {Froyen, Vicky},\n",
      " notes = {Empty},\n",
      " school = {Rutgers University-Graduate School-New Brunswick},\n",
      " title = {Bayesian mixture estimation for perceptual grouping},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{Furnas1987,\n",
      " abstract = {Empty},\n",
      " author = {Furnas, George W. and Landauer, Thomas K. and Gomez, Louis M. and Dumais, Susan T.},\n",
      " journal = {Communications of the ACM},\n",
      " notes = {Empty},\n",
      " number = {11},\n",
      " pages = {964--971},\n",
      " publisher = {ACM},\n",
      " title = {The vocabulary problem in human-system communication},\n",
      " url = {#},\n",
      " volume = {30},\n",
      " year = {1987}\n",
      "}\n",
      "\n",
      "@article{furnas1987vocabulary,\n",
      " abstract = {Empty},\n",
      " author = {Furnas, George W. and Landauer, Thomas K. and Gomez, Louis M. and Dumais, Susan T.},\n",
      " journal = {Communications of the ACM},\n",
      " notes = {Empty},\n",
      " number = {11},\n",
      " pages = {964--971},\n",
      " publisher = {ACM},\n",
      " title = {The vocabulary problem in human-system communication},\n",
      " url = {#},\n",
      " volume = {30},\n",
      " year = {1987}\n",
      "}\n",
      "\n",
      "@article{gale1995good,\n",
      " abstract = {Empty},\n",
      " author = {Gale, William and Sampson, Geoffrey},\n",
      " journal = {Journal of Quantitative Linguistics},\n",
      " notes = {Empty},\n",
      " number = {3},\n",
      " pages = {217--237},\n",
      " title = {Good-Turing smoothing without tears},\n",
      " url = {#},\n",
      " volume = {2},\n",
      " year = {1995}\n",
      "}\n",
      "\n",
      "@book{gardenfors2004conceptual,\n",
      " abstract = {Empty},\n",
      " author = {Gärdenfors, Peter},\n",
      " notes = {Empty},\n",
      " title = {Conceptual spaces: The geometry of thought},\n",
      " url = {#},\n",
      " year = {2004}\n",
      "}\n",
      "\n",
      "@book{gardenfors:spaces,\n",
      " abstract = {Empty},\n",
      " author = {Peter {G̈ardenfors}},\n",
      " notes = {Empty},\n",
      " publisher = {MIT},\n",
      " title = {Conceptual Spaces},\n",
      " url = {#},\n",
      " year = {2000}\n",
      "}\n",
      "\n",
      "@article{gelman1996efficient,\n",
      " abstract = {Empty},\n",
      " author = {Gelman, A and Roberts, G and Gilks, W},\n",
      " notes = {Empty},\n",
      " title = {Efficient metropolis jumping hules},\n",
      " url = {#},\n",
      " year = {1996}\n",
      "}\n",
      "\n",
      "@inproceedings{genw-paper,\n",
      " abstract = {Empty},\n",
      " author = {Matthew Stone and Bonnie Webber},\n",
      " booktitle = {Proceedings of International Natural Language\n",
      "Generation Workshop},\n",
      " notes = {Empty},\n",
      " pages = {178--187},\n",
      " title = {Textual economy through close coupling of syntax and semantics},\n",
      " url = {#},\n",
      " year = {1998}\n",
      "}\n",
      "\n",
      "@article{GijsenijTIP2011,\n",
      " abstract = {Empty},\n",
      " author = {Gijsenij, A. and Gevers, T. and van de Weijer, J.},\n",
      " journal = {IEEE Transactions on Image Processing},\n",
      " notes = {Empty},\n",
      " number = {9},\n",
      " pages = {2475--2489},\n",
      " title = {Computational Color Constancy: Survey and Experiments},\n",
      " url = {#},\n",
      " volume = {20},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@inproceedings{girshick2014rich,\n",
      " abstract = {Empty},\n",
      " author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jagannath},\n",
      " booktitle = {Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {580--587},\n",
      " title = {Rich feature hierarchies for accurate object detection and semantic segmentation},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{goodman2015probabilistic,\n",
      " abstract = {Empty},\n",
      " author = {Goodman, Noah D and Lassiter, Daniel},\n",
      " journal = {Handbook of contemporary semantics. Wiley-Blackwell},\n",
      " notes = {Empty},\n",
      " title = {Probabilistic semantics and pragmatics: Uncertainty in language and thought},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@article{GorniakRoy04,\n",
      " abstract = {Empty},\n",
      " author = {Peter Gorniak and\n",
      "Deb Roy},\n",
      " bibsource = {DBLP, http://dblp.uni-trier.de},\n",
      " ee = {http://dx.doi.org/10.1613/jair.1327},\n",
      " journal = {Journal of Artificial Intelligence Research (JAIR)},\n",
      " notes = {Empty},\n",
      " pages = {429-470},\n",
      " title = {Grounded Semantic Composition for Visual Scenes},\n",
      " url = {#},\n",
      " volume = {21},\n",
      " year = {2004}\n",
      "}\n",
      "\n",
      "@article{graff:pt00,\n",
      " abstract = {Empty},\n",
      " author = {Delia Graff Fara},\n",
      " journal = {Philosophical Topics},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {45--81},\n",
      " title = {Shifting sands: An interest-relative theory of vagueness},\n",
      " url = {#},\n",
      " volume = {28},\n",
      " year = {2000}\n",
      "}\n",
      "\n",
      "@incollection{grice,\n",
      " abstract = {Empty},\n",
      " address = {New York},\n",
      " author = {Herbert P. Grice},\n",
      " booktitle = {Syntax and Semantics III: Speech Acts},\n",
      " editor = {P. Cole and J. Morgan},\n",
      " notes = {Empty},\n",
      " pages = {41--58},\n",
      " publisher = {Academic Press},\n",
      " title = {Logic and Conversation},\n",
      " url = {#},\n",
      " year = {1975}\n",
      "}\n",
      "\n",
      "@inproceedings{gutmann2010noise,\n",
      " abstract = {We present a new estimation principle for\n",
      "parameterized statistical models. The idea\n",
      "is to perform nonlinear logistic regression to\n",
      "discriminate between the observed data and\n",
      "some artificially generated noise, using the\n",
      "model log-density function in the regression\n",
      "nonlinearity. We show that this leads to a\n",
      "consistent (convergent) estimator of the parameters,\n",
      "and analyze the asymptotic variance.\n",
      "In particular, the method is shown to\n",
      "directly work for unnormalized models, i.e.\n",
      "models where the density function does not\n",
      "integrate to one. The normalization constant\n",
      "can be estimated just like any other parameter.\n",
      "For a tractable ICA model, we compare\n",
      "the method with other estimation methods\n",
      "that can be used to learn unnormalized models,\n",
      "including score matching, contrastive divergence,\n",
      "and maximum-likelihood where the\n",
      "normalization constant is estimated with importance\n",
      "sampling. Simulations show that\n",
      "noise-contrastive estimation offers the best\n",
      "trade-off between computational and statistical\n",
      "efficiency. The method is then applied\n",
      "to the modeling of natural images: We show\n",
      "that the method can successfully estimate\n",
      "a large-scale two-layer model and a Markov\n",
      "random field.},\n",
      " author = {Gutmann, Michael and Hyvärinen, Aapo},\n",
      " booktitle = {International Conference on Artificial Intelligence and Statistics},\n",
      " notes = {Empty},\n",
      " pages = {297--304},\n",
      " title = {Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},\n",
      " url = {#},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@article{Harnad1990,\n",
      " abstract = {Empty},\n",
      " author = {Harnad, Stevan},\n",
      " journal = {Physica D: Nonlinear Phenomena},\n",
      " notes = {Empty},\n",
      " title = {{The symbol grounding problem}},\n",
      " url = {#},\n",
      " year = {1990}\n",
      "}\n",
      "\n",
      "@inproceedings{heess2012actor,\n",
      " abstract = {We consider reinforcement learning in Markov decision processes with high dimensional\n",
      "state and action spaces. We parametrize policies using energy-based models (particularly\n",
      "restricted Boltzmann machines), and train them using policy gradient learning. Our approach\n",
      "builds upon Sallans and Hinton (2004), who parameterized value functions using\n",
      "energy-based models, trained using a non-linear variant of temporal-difference (TD) learning.\n",
      "Unfortunately, non-linear TD is known to diverge in theory and practice. We introduce\n",
      "the first sound and efficient algorithm for training energy-based policies, based on an actorcritic\n",
      "architecture. Our algorithm is computationally efficient, converges close to a local\n",
      "optimum, and outperforms Sallans and Hinton (2004) in several high dimensional domains.},\n",
      " author = {Heess, Nicolas and Silver, David and Teh, Yee Whye},\n",
      " booktitle = {EWRL},\n",
      " notes = {Empty},\n",
      " organization = {Citeseer},\n",
      " pages = {43--58},\n",
      " title = {Actor-Critic Reinforcement Learning with Energy-Based Policies.},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@inproceedings{hemmer2015inferring,\n",
      " abstract = {Empty},\n",
      " author = {Hemmer, Pernille and Persaud, Kimele and Kidd, Celeste and Piantadosi, Steven T},\n",
      " notes = {Empty},\n",
      " title = {Inferring the Tsimane's use of color categories from recognition memory.},\n",
      " url = {#},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@article{Hinton2007,\n",
      " abstract = {To achieve its impressive performance in tasks such as speech perception or object recognition, the brain extracts multiple levels of representation from the sensory input. Backpropagation was the first computationally efficient model of how neural networks could learn multiple layers of representation, but it required labeled training data and it did not work well in deep networks. The limitations of backpropagation learning can now be overcome by using multilayer neural networks that contain top-down connections and training them to generate sensory data rather than to classify it. Learning multilayer generative models might seem difficult, but a recent discovery makes it easy to learn nonlinear distributed representations one layer at a time.},\n",
      " author = {Hinton, Geoffrey E},\n",
      " doi = {10.1016/j.tics.2007.09.004},\n",
      " file = {:C$\\backslash$:/research/papers/deep networks/ticsdraft.pdf:pdf},\n",
      " issn = {1364-6613},\n",
      " journal = {Trends in cognitive sciences},\n",
      " keywords = {Brain,Brain: physiology,Humans,Learning,Learning: physiology,Models, Psychological,Nerve Net,Nerve Net: physiology},\n",
      " month = {October},\n",
      " notes = {Empty},\n",
      " number = {10},\n",
      " pages = {428--34},\n",
      " pmid = {17921042},\n",
      " title = {{Learning multiple layers of representation.}},\n",
      " url = {#},\n",
      " volume = {11},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@book{hirschberg1985theory,\n",
      " abstract = {Empty},\n",
      " author = {Hirschberg, Julia Linn Bell},\n",
      " notes = {Empty},\n",
      " publisher = {University of Pennsylvania},\n",
      " title = {A theory of scalar implicature},\n",
      " url = {#},\n",
      " year = {1985}\n",
      "}\n",
      "\n",
      "@article{hodosh2013framing,\n",
      " abstract = {The ability to associate images with natural language sentences that describe what is depicted in them is a hallmark of image understanding, and a prerequisite for applications such as sentence-based image search. In analogy to image search, we propose to frame sentence-based image annotation as the task of ranking a given pool of captions. We introduce a new benchmark collection for sentence-based image description and search, consisting of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events. We introduce a number of systems that perform quite well on this task, even though they are only based on features that can be obtained with minimal supervision. Our results clearly indicate the importance of training on multiple captions per image, and of capturing syntactic (word order-based) and semantic features of these captions. We also perform an in-depth comparison of human and automatic evaluation metrics for this task, and propose strategies for collecting human judgments cheaply and on a very large scale, allowing us to augment our collection with additional relevance judgments of which captions describe which image. Our analysis shows that metrics that consider the ranked list of results for each query image or sentence are significantly more robust than metrics that are based on a single response per query. Moreover, our study suggests that the evaluation of ranking-based image description systems may be fully automated.},\n",
      " author = {Hodosh, Micah and Young, Peter and Hockenmaier, Julia},\n",
      " journal = {Journal of Artificial Intelligence Research},\n",
      " notes = {Empty},\n",
      " pages = {853--899},\n",
      " title = {Framing image description as a ranking task: Data, models and evaluation metrics},\n",
      " url = {http://www.jair.org/media/3994/live-3994-7274-jair.pdf},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{Hodosh2014,\n",
      " abstract = {Empty},\n",
      " author = {Hodosh, PYALM and Hockenmaier, Julia},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/young_etal_tacl_2014.pdf:pdf},\n",
      " journal = {nlp.cs.illinois.edu},\n",
      " notes = {Empty},\n",
      " pages = {67--78},\n",
      " title = {{From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions}},\n",
      " url = {#},\n",
      " volume = {2},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{horn1989natural,\n",
      " abstract = {Empty},\n",
      " author = {Horn, Laurence},\n",
      " notes = {Empty},\n",
      " title = {A natural history of negation},\n",
      " url = {#},\n",
      " year = {1989}\n",
      "}\n",
      "\n",
      "@book{hughes2013,\n",
      " abstract = {Empty},\n",
      " author = {John F. Hughes and Andries van Dam and Morgan\n",
      "McGuire and David F. Sklar and James D. Foley and\n",
      "Steven K. Feiner and Kurt Akeley},\n",
      " notes = {Empty},\n",
      " publisher = {Addison-Wesley Professional},\n",
      " title = {Computer Graphics: Principles and Practice (3rd Edition)},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@inproceedings{imagenet_cvpr09,\n",
      " abstract = {Empty},\n",
      " author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},\n",
      " booktitle = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {248--255},\n",
      " title = {Imagenet: A large-scale hierarchical image database},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@book{Jackendoff1983,\n",
      " abstract = {Empty},\n",
      " author = {Jackendoff, Ray},\n",
      " notes = {Empty},\n",
      " publisher = {MIT press},\n",
      " title = {Semantics and cognition},\n",
      " url = {#},\n",
      " volume = {8},\n",
      " year = {1983}\n",
      "}\n",
      "\n",
      "@misc{jackendoff1983,\n",
      " abstract = {Empty},\n",
      " author = {Jackendoff, RS},\n",
      " notes = {Empty},\n",
      " publisher = {MIT Press},\n",
      " title = {Semantics and Cognition},\n",
      " url = {#},\n",
      " year = {1983}\n",
      "}\n",
      "\n",
      "@incollection{jager2010natural,\n",
      " abstract = {Empty},\n",
      " author = {Jäger, Gerhard},\n",
      " booktitle = {Logic, language and meaning},\n",
      " notes = {Empty},\n",
      " pages = {11--20},\n",
      " publisher = {Springer},\n",
      " title = {Natural color categories are convex sets},\n",
      " url = {#},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@inproceedings{jager:ac09,\n",
      " abstract = {Empty},\n",
      " author = {Gerhard Jäger},\n",
      " bibsource = {DBLP, http://dblp.uni-trier.de},\n",
      " booktitle = {Logic, Language and Meaning - 17th Amsterdam Colloquium,\n",
      "Amsterdam, The Netherlands, December 16-18, 2009, Revised\n",
      "Selected Papers},\n",
      " editor = {Maria Aloni and\n",
      "Harald Bastiaanse and\n",
      "Tikitu de Jager and\n",
      "Katrin Schulz},\n",
      " ee = {http://dx.doi.org/10.1007/978-3-642-14287-1_2},\n",
      " notes = {Empty},\n",
      " pages = {11-20},\n",
      " publisher = {Springer},\n",
      " series = {Lecture Notes in Computer Science},\n",
      " title = {Natural Color Categories Are Convex Sets},\n",
      " url = {#},\n",
      " volume = {6042},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@article{jelinek1977perplexity,\n",
      " abstract = {Empty},\n",
      " author = {Jelinek, Fred and Mercer, Robert L. and Bahl, Lalit R. and Baker, James K.},\n",
      " journal = {The Journal of the Acoustical Society of America},\n",
      " notes = {Empty},\n",
      " pages = {S63},\n",
      " title = {Perplexity--a measure of the difficulty of speech recognition tasks},\n",
      " url = {#},\n",
      " volume = {62},\n",
      " year = {1977}\n",
      "}\n",
      "\n",
      "@incollection{joshi1997tree,\n",
      " abstract = {Empty},\n",
      " author = {Joshi, Aravind K and Schabes, Yves},\n",
      " booktitle = {Handbook of formal languages},\n",
      " notes = {Empty},\n",
      " pages = {69--123},\n",
      " publisher = {Springer},\n",
      " title = {Tree-adjoining grammars},\n",
      " url = {#},\n",
      " year = {1997}\n",
      "}\n",
      "\n",
      "@inproceedings{karpathy2014deep,\n",
      " abstract = {Empty},\n",
      " author = {Karpathy, Andrej and Joulin, Armand and Li, Fei Fei F},\n",
      " booktitle = {Advances in neural information processing systems},\n",
      " notes = {Empty},\n",
      " pages = {1889--1897},\n",
      " title = {Deep fragment embeddings for bidirectional image sentence mapping},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@inproceeds{karpathy2015deep,\n",
      " abstract = {Empty},\n",
      " author = {Karpathy, Andrej and Fei-Fei, Li},\n",
      " booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n",
      " notes = {Empty},\n",
      " pages = {},\n",
      " title = {Deep visual-semantic alignments for generating image descriptions},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@inproceedings{Kate2007,\n",
      " abstract = {This paper presents a method for learning a semantic parser from ambiguous supervision. Training data consists of natural language sentences annotated with multiple potential meaning representations, only one of which is correct. Such ambiguous supervision models the type of supervision that can be more naturally available to language-learning systems. Given such weak supervision, our approach produces a semantic parser that maps sentences into meaning representations. An existing semantic parsing learning system that can only learn from unambiguous supervision is augmented to handle ambiguous supervision. Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers.},\n",
      " author = {Kate, Rohit J and Mooney, Raymond J},\n",
      " booktitle = {Artificial Intelligence},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/kate_mooney-aaai-07.pdf:pdf},\n",
      " isbn = {9781577353232},\n",
      " mendeley-groups = {possqualsrefs},\n",
      " notes = {Empty},\n",
      " pages = {895--900},\n",
      " title = {{Learning Language Semantics from Ambiguous Supervision}},\n",
      " url = {#},\n",
      " volume = {22},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@book{kay09,\n",
      " abstract = {Empty},\n",
      " author = {Paul Kay and Brent Berlin and Luisa Maffi and William R. Merrifield and Richard Cook},\n",
      " notes = {Empty},\n",
      " publisher = {CSLI},\n",
      " title = {The World Color Survey},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@article{kazemzadeh2014referitgame,\n",
      " abstract = {Empty},\n",
      " author = {Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara L},\n",
      " journal = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n",
      " notes = {Empty},\n",
      " pages = {787--798},\n",
      " title = {Referitgame: Referring to objects in photographs of natural scenes},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{kennedy-mcnally:2010,\n",
      " abstract = {Empty},\n",
      " author = {Chris Kennedy and Louise McNally},\n",
      " journal = {Synthese},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {79--98},\n",
      " title = {Color, Context and Compositionality},\n",
      " url = {#},\n",
      " volume = {174},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@article{kennedy2007vagueness,\n",
      " abstract = {Empty},\n",
      " author = {Kennedy, Christopher},\n",
      " journal = {Linguistics and philosophy},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {1--45},\n",
      " publisher = {Springer},\n",
      " title = {Vagueness and grammar: The semantics of relative and absolute gradable adjectives},\n",
      " url = {#},\n",
      " volume = {30},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{kennedy2010color,\n",
      " abstract = {Empty},\n",
      " author = {Kennedy, Christopher and McNally, Louise},\n",
      " journal = {Synthese},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {79--98},\n",
      " publisher = {Springer},\n",
      " title = {Color, context, and compositionality},\n",
      " url = {#},\n",
      " volume = {174},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@article{kennedy:lp07,\n",
      " abstract = {Empty},\n",
      " author = {Christopher Kennedy},\n",
      " journal = {Linguistics and Philosophy},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {1--45},\n",
      " title = {Vagueness and grammar: the semantics of relative and absolute gradable adjectives},\n",
      " url = {#},\n",
      " volume = {30},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{kennington2015real,\n",
      " abstract = {Empty},\n",
      " author = {Kennington, Casey and Lopez Gambino, Maria Soledad and Schlangen, David},\n",
      " notes = {Empty},\n",
      " title = {Real-world Reference Game using the Words-as-Classifiers Model of Reference Resolution},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@inproceedings{kiros2014multimodal,\n",
      " abstract = {Empty},\n",
      " author = {Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Rich},\n",
      " booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},\n",
      " notes = {Empty},\n",
      " pages = {595--603},\n",
      " title = {Multimodal neural language models},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@inproceedings{kiros2014multiplicative,\n",
      " abstract = {Empty},\n",
      " author = {Kiros, Ryan and Zemel, Richard and Salakhutdinov, Ruslan R},\n",
      " booktitle = {Advances in Neural Information Processing Systems},\n",
      " notes = {Empty},\n",
      " pages = {2348--2356},\n",
      " title = {A multiplicative model for learning distributed text-based attribute representations},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{kiros2014unifying,\n",
      " abstract = {Empty},\n",
      " author = {Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Richard S},\n",
      " journal = {arXiv preprint arXiv:1411.2539},\n",
      " notes = {Empty},\n",
      " title = {Unifying visual-semantic embeddings with multimodal neural language models},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@inproceedings{klein2012inverse,\n",
      " abstract = {This paper adresses the inverse reinforcement learning (IRL) problem, that is inferring\n",
      "a reward for which a demonstrated expert behavior is optimal. We introduce\n",
      "a new algorithm, SCIRL, whose principle is to use the so-called feature\n",
      "expectation of the expert as the parameterization of the score function of a multiclass\n",
      "classifier. This approach produces a reward function for which the expert\n",
      "policy is provably near-optimal. Contrary to most of existing IRL algorithms,\n",
      "SCIRL does not require solving the direct RL problem. Moreover, with an appropriate\n",
      "heuristic, it can succeed with only trajectories sampled according to the\n",
      "expert behavior. This is illustrated on a car driving simulator.},\n",
      " author = {Klein, Edouard and Geist, Matthieu and Piot, Bilal and Pietquin, Olivier},\n",
      " booktitle = {Advances in Neural Information Processing Systems},\n",
      " notes = {Empty},\n",
      " pages = {1007--1015},\n",
      " title = {Inverse reinforcement learning through structured classification},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{klein:80,\n",
      " abstract = {Empty},\n",
      " author = {Ewan Klein},\n",
      " journal = {Linguistics and Philosophy},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {1--45},\n",
      " title = {A semantics for positive and comparative adjectives},\n",
      " url = {#},\n",
      " volume = {4},\n",
      " year = {1980}\n",
      "}\n",
      "\n",
      "@inproceedings{Kollar2010,\n",
      " abstract = {Empty},\n",
      " author = {Kollar, Thomas and Tellex, Stefanie and Roy, Deb and Roy, Nicholas},\n",
      " booktitle = {Human-Robot Interaction (HRI), 2010 5th ACM/IEEE International Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {259--266},\n",
      " title = {Toward understanding natural language directions},\n",
      " url = {#},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@article{krahmer:cl12,\n",
      " abstract = {Empty},\n",
      " author = {Emiel Krahmer and\n",
      "Kees van Deemter},\n",
      " journal = {Computational Linguistics},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {173--218},\n",
      " title = {Computational Generation of Referring Expressions: A Survey},\n",
      " url = {#},\n",
      " volume = {38},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@inproceedings{Krishnamurthy2012,\n",
      " abstract = {Empty},\n",
      " author = {Krishnamurthy, Jayant and Mitchell, Tom M},\n",
      " booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/krishnamurthy-emnlp2012.pdf:pdf},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {754--765},\n",
      " title = {Weakly supervised training of semantic parsers},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{Krishnamurthy2013,\n",
      " abstract = {Empty},\n",
      " annote = {per predicate binary classifiers\n",
      "with this, there is no notion of what words are more preferred (blue vs light blue, etc)\n",
      "every predicate must be applies to every entity\n",
      "entities are assumed given\n",
      "\n",
      "\n",
      "the mapping from environment to representation space differs by domain\n",
      "-in the scene, it is HOG and RGB color his\n",
      "-in the map, it is distributional semantics, and spatial features\n",
      "\n",
      "},\n",
      " author = {Krishnamurthy, Jayant and Kollar, Thomas},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/krishnamurthy_kollar_tacl_2013_parseperceive.pdf:pdf},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {193--206},\n",
      " title = {Jointly learning to parse and perceive: Connecting natural language to the physical world},\n",
      " url = {#},\n",
      " volume = {1},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{krishnamurthy2013jointly,\n",
      " abstract = {Empty},\n",
      " author = {Krishnamurthy, Jayant and Kollar, Thomas},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " pages = {193--206},\n",
      " title = {Jointly learning to parse and perceive: Connecting natural language to the physical world},\n",
      " url = {#},\n",
      " volume = {1},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@inproceedings{krizhevsky2012imagenet,\n",
      " abstract = {Empty},\n",
      " author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},\n",
      " booktitle = {Advances in neural information processing systems},\n",
      " notes = {Empty},\n",
      " pages = {1097--1105},\n",
      " title = {Imagenet classification with deep convolutional neural networks},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@inproceedings{kulkarni2011baby,\n",
      " abstract = {Empty},\n",
      " author = {Kulkarni, Girish and Premraj, Visruth and Dhar, Sagnik and Li, Siming and Choi, Yejin and Berg, Alexander C and Berg, Tamara L},\n",
      " booktitle = {Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {1601--1608},\n",
      " title = {Baby talk: Understanding and generating simple image descriptions},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@inproceedings{kwiatkowski-EtAl:2011:EMNLP,\n",
      " abstract = {Empty},\n",
      " address = {Edinburgh, Scotland, UK.},\n",
      " author = {Kwiatkowski, Tom  and  Zettlemoyer, Luke  and  Goldwater, Sharon  and  Steedman, Mark},\n",
      " booktitle = {Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing},\n",
      " month = {July},\n",
      " notes = {Empty},\n",
      " pages = {1512--1523},\n",
      " publisher = {Association for Computational Linguistics},\n",
      " title = {Lexical Generalization in CCG Grammar Induction for Semantic Parsing},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{kyburg/morreau:lp00,\n",
      " abstract = {Empty},\n",
      " author = {Alice Kyburg and Michael Morreau},\n",
      " journal = {Linguistics and Philosophy},\n",
      " notes = {Empty},\n",
      " number = {6},\n",
      " pages = {577-597},\n",
      " title = {Fitting words: Vague words in context},\n",
      " url = {#},\n",
      " volume = {23},\n",
      " year = {2000}\n",
      "}\n",
      "\n",
      "@phdthesis{Lammens1994,\n",
      " abstract = {Empty},\n",
      " author = {Lammens, Johan Maurice Gisele},\n",
      " notes = {Empty},\n",
      " school = {Citeseer},\n",
      " title = {A computational model of color perception and color naming},\n",
      " url = {#},\n",
      " year = {1994}\n",
      "}\n",
      "\n",
      "@inproceedings{Lampert2009,\n",
      " abstract = {Empty},\n",
      " annote = {Very similar to farhadi.  Uses attributes to create classifiers that can detect unseen object classes},\n",
      " author = {Lampert, Christoph H and Nickisch, Hannes and Harmeling, Stefan},\n",
      " booktitle = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},\n",
      " doi = {10.1109/CVPR.2009.5206594},\n",
      " file = {:C$\\backslash$:/research/papers/computer vision/lampert_cvpr_2009_attributes.pdf:pdf},\n",
      " isbn = {978-1-4244-3992-8},\n",
      " month = {June},\n",
      " notes = {Empty},\n",
      " pages = {951--958},\n",
      " publisher = {IEEE},\n",
      " title = {{Learning to detect unseen object classes by between-class attribute transfer}},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@article{larsson:jlc13,\n",
      " abstract = {Empty},\n",
      " author = {Staffan Larsson},\n",
      " journal = {Journal of Logic and Computation},\n",
      " notes = {Empty},\n",
      " title = {Formal semantics for perceptual classification},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@inproceedings{Lassiter09a,\n",
      " abstract = {Empty},\n",
      " author = {Daniel Lassiter},\n",
      " bibsource = {DBLP, http://dblp.uni-trier.de},\n",
      " booktitle = {Vagueness in Communication - International Workshop, ViC\n",
      "2009, held as part of ESSLLI 2009, Bordeaux, France, July\n",
      "20-24, 2009. Revised Selected Papers},\n",
      " editor = {Rick Nouwen and\n",
      "Robert van Rooij and\n",
      "Uli Sauerland and\n",
      "Hans-Christian Schmitz},\n",
      " ee = {http://dx.doi.org/10.1007/978-3-642-18446-8_8},\n",
      " notes = {Empty},\n",
      " pages = {127-150},\n",
      " publisher = {Springer},\n",
      " series = {Lecture Notes in Computer Science},\n",
      " title = {Vagueness as Probabilistic Linguistic Knowledge},\n",
      " url = {#},\n",
      " volume = {6517},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@inproceedings{lassiter2009vagueness,\n",
      " abstract = {Empty},\n",
      " author = {Lassiter, Daniel},\n",
      " booktitle = {International Workshop on Vagueness in Communication},\n",
      " notes = {Empty},\n",
      " organization = {Springer},\n",
      " pages = {127--150},\n",
      " title = {Vagueness as probabilistic linguistic knowledge},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@incollection{lassiter2011vagueness,\n",
      " abstract = {Empty},\n",
      " author = {Lassiter, Daniel},\n",
      " booktitle = {Vagueness in communication},\n",
      " notes = {Empty},\n",
      " pages = {127--150},\n",
      " publisher = {Springer},\n",
      " title = {Vagueness as probabilistic linguistic knowledge},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{leffelvagueness,\n",
      " abstract = {While vagueness and implicature are two of the most studied topics in semantics and pragmatics, their interaction has received little attention in the literature. Part of what makes this an interest- ing domain of investigation is that both implicature and vagueness involve an inherent amount of interpretive uncertainty: with vagueness, there is uncertainty about whether a predicate applies to an object; with implicature, there is uncertainty about whether a candidate inference was intended by the speaker. Gradable adjectives provide an ideal domain for investigating how multiple sources of uncertainty interact in semantic/pragmatic interpretation. In this paper, we argue that interaction between vagueness and implicature is the source of a puzzling and, to our knowledge heretofore unobserved, asymmetry between the interpretations of different classes of intensified gradable adjectives under negation. Specifically, the interpretation of sentences containing the collocation not very ADJ varies depending upon whether ADJ is a relative standard gradable adjective (e.g. tall) or a (minimum standard) absolute gradable adjective (e.g. late), in the sense of Kennedy & McNally (2005); Kennedy (2007); a.o. We first report an experiment investigating the interpretation of not very ADJ and related expressions across these two adjective types. Our results provide strong evidence that not very ADJ gives rise to an ADJ-implicature for minimum standard adjectives like late but not for relative standard adjectives like tall. We propose that this asymmetry follows from an interaction between scale structure and a novel constraint on implicature calculation according to which implicatures are not derived if they lead to “borderline contradictions” (Ripley 2011; Alxatib & Pelletier 2011; a.o.). We then provide evidence for this hypothesis based on reconstructed interpretations of logically complex predicates from the experimental data. In sum, the interpretive asymmetry is reducible to differences in scale structure and vagueness: relative adjectives are vague in a way that absolute adjectives are not, which we argue affects the relative likelihood that an implicature will be generated},\n",
      " author = {Leffel, Timothy and Cremers, Alexandre and Gotzner, Nicole and Romoli, Jacopo},\n",
      " notes = {Empty},\n",
      " title = {Vagueness and the derivation of structural implicatures},\n",
      " url = {http://semanticsarchive.net/Archive/mM1Yzc5Y/vagueness-implicature-LCGR-2016.pdf},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@inproceedings{levy2014dependencybased,\n",
      " abstract = {Empty},\n",
      " author = {Levy, Omer and Goldberg, Yoav},\n",
      " booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " pages = {302--308},\n",
      " title = {Dependencybased word embeddings},\n",
      " url = {#},\n",
      " volume = {2},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{levy2015improving,\n",
      " abstract = {Recent trends suggest that neuralnetwork-inspired\n",
      "word embedding models\n",
      "outperform traditional count-based distributional\n",
      "models on word similarity and\n",
      "analogy detection tasks. We reveal that\n",
      "much of the performance gains of word\n",
      "embeddings are due to certain system\n",
      "design choices and hyperparameter optimizations,\n",
      "rather than the embedding\n",
      "algorithms themselves. Furthermore,\n",
      "we show that these modifications can be\n",
      "transferred to traditional distributional\n",
      "models, yielding similar gains. In contrast\n",
      "to prior reports, we observe mostly local\n",
      "or insignificant performance differences\n",
      "between the methods, with no global\n",
      "advantage to any single approach over the\n",
      "others.},\n",
      " author = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " pages = {211--225},\n",
      " title = {Improving distributional similarity with lessons learned from word embeddings},\n",
      " url = {#},\n",
      " volume = {3},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@article{lewis:1979,\n",
      " abstract = {Empty},\n",
      " author = {David Lewis},\n",
      " journal = {Journal of Philosophical Logic},\n",
      " notes = {Empty},\n",
      " pages = {339--359},\n",
      " title = {Scorekeeping in a Language Game},\n",
      " url = {#},\n",
      " volume = {8},\n",
      " year = {1979}\n",
      "}\n",
      "\n",
      "@book{lewis:convention,\n",
      " abstract = {Empty},\n",
      " address = {Cambridge, MA},\n",
      " author = {David K. Lewis},\n",
      " notes = {Empty},\n",
      " publisher = {Harvard University Press},\n",
      " title = {Convention: A Philosophical Study},\n",
      " url = {#},\n",
      " year = {1969}\n",
      "}\n",
      "\n",
      "@incollection{lin2014microsoft,\n",
      " abstract = {Empty},\n",
      " author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C Lawrence},\n",
      " booktitle = {Computer Vision--ECCV 2014},\n",
      " notes = {Empty},\n",
      " pages = {740--755},\n",
      " publisher = {Springer},\n",
      " title = {Microsoft COCO: Common objects in context},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@incollection{lopes2009active,\n",
      " abstract = {Inverse reinforcement learning addresses the general problem of recovering a reward function from samples of a policy provided by an expert/demonstrator.  In this paper, we introduce active learning for inverse reinforcement learning.  We propose an algorithm that allows the agent to query the demonstrator for samples at specific states, instead of relying only on samples provided at \"arbitrary\" states.  The purpose of our algorithm is to estimate the reward function with similar accuracy as other methods from the literature while reducing the amount of policy samples required from the expert.  We also discuss the use of our algorithm in higher dimensional problems, using both Monte Carlo and gradient methods.  We present illustrative results of our algorithm in several simulated examples of different complexities.},\n",
      " author = {Lopes, Manuel and Melo, Francisco and Montesano, Luis},\n",
      " booktitle = {Machine Learning and Knowledge Discovery in Databases},\n",
      " notes = {introduces MLIRL in this paper},\n",
      " pages = {31--46},\n",
      " publisher = {Springer},\n",
      " title = {Active learning for reward estimation in inverse reinforcement learning},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@article{Lowe2004,\n",
      " abstract = {Empty},\n",
      " author = {Lowe, David G.},\n",
      " doi = {10.1023/B:VISI.0000029664.99615.94},\n",
      " file = {:C$\\backslash$:/research/papers/computer vision/lowe_sift_ijcv04.pdf:pdf},\n",
      " issn = {0920-5691},\n",
      " journal = {International Journal of Computer Vision},\n",
      " month = {November},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {91--110},\n",
      " title = {{Distinctive Image Features from Scale-Invariant Keypoints}},\n",
      " url = {#},\n",
      " volume = {60},\n",
      " year = {2004}\n",
      "}\n",
      "\n",
      "@book{ludlow:lexicon,\n",
      " abstract = {Empty},\n",
      " address = {Oxford},\n",
      " author = {Peter Ludlow},\n",
      " notes = {Empty},\n",
      " publisher = {Oxford University Press},\n",
      " title = {Living Words: Meaning Underdetermination and the Dynamic Lexicon},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{Luong2013,\n",
      " abstract = {Empty},\n",
      " author = {Luong, Minh-thang and Frank, Michael C},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/luong_frank_johnson_tacl_2013_discourseingroundedlanguage.pdf:pdf},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {315--326},\n",
      " title = {{Parsing entire discourses as very long strings : Capturing topic continuity in grounded language learning}},\n",
      " url = {#},\n",
      " volume = {1},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@inproceedings{macias2015memory,\n",
      " abstract = {Empty},\n",
      " author = {Macias, Carla and Yung, Amanda and Hemmer, Pernille and Kidd, Celeste},\n",
      " notes = {Empty},\n",
      " title = {Memory Strategically Encodes Externally Unavailable Information.},\n",
      " url = {#},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@article{MacMahon2006,\n",
      " abstract = {Empty},\n",
      " author = {MacMahon, Matt and Stankiewicz, Brian and Kuipers, Benjamin},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/macmahon_aaai_06.pdf:pdf},\n",
      " journal = {Def},\n",
      " keywords = {integrated intelligent capabilities,special track},\n",
      " notes = {Empty},\n",
      " pages = {1475--1482},\n",
      " title = {{Walk the talk: Connecting language, knowledge, and action in route instructions}},\n",
      " url = {#},\n",
      " year = {2006}\n",
      "}\n",
      "\n",
      "@inproceedings{magerman1995statistical,\n",
      " abstract = {Empty},\n",
      " author = {Magerman, David M},\n",
      " booktitle = {Proceedings of the 33rd annual meeting on Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {276--283},\n",
      " title = {Statistical decision-tree models for parsing},\n",
      " url = {#},\n",
      " year = {1995}\n",
      "}\n",
      "\n",
      "@inproceedings{mano2016scene,\n",
      " abstract = {Synthesizing a new image from verbal information is a challenging task that has a number of applications. Most research on the issue has attempted to address this question by providing external clues, such as sketches. However, no study has been able to successfully handle various sentences for this purpose without any other information. We propose a system to synthesize scene images solely from sentences. Input sentences are expected to be complete sentences with visualizable objects. Our priorities are the analysis of sentences and the correlation of information between input sentences and visible image patches. A hierarchical syntactic parser is developed for sentence analysis, and a combination of lexical knowledge and corpus statistics is designed for word correlation. The entire system was applied to both a clip-art dataset and an actual image dataset. This application highlighted the capability of the proposed system to generate novel images as well as its ability to succinctly convey ideas.},\n",
      " author = {Mano, Tetsuaki and Yamane, Hiroaki and Harada, Tatsuya},\n",
      " booktitle = {Proceedings of the 2016 ACM on Multimedia Conference},\n",
      " notes = {Empty},\n",
      " organization = {ACM},\n",
      " pages = {112--116},\n",
      " title = {Scene Image Synthesis from Natural Sentences Using Hierarchical Syntactic Analysis},\n",
      " url = {http://dl.acm.org/citation.cfm?id=2967193},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{mao2015generation,\n",
      " abstract = {Empty},\n",
      " author = {Mao, Junhua and Huang, Jonathan and Toshev, Alexander and Camburu, Oana and Yuille, Alan and Murphy, Kevin},\n",
      " journal = {arXiv preprint arXiv:1511.02283},\n",
      " notes = {Empty},\n",
      " title = {Generation and Comprehension of Unambiguous Object Descriptions},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@misc{marekrei:nnlmlecture,\n",
      " abstract = {Empty},\n",
      " author = {Marek Rei},\n",
      " notes = {Empty},\n",
      " title = {Machine Learning for Language Modelling; Part 3: NNLM (slides)},\n",
      " url = {#},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@inproceedings{Matuszek2012,\n",
      " abstract = {Empty},\n",
      " author = {Matuszek, Cynthia and Fitzgerald, Nicholas and Zettlemoyer, Luke and Bo, Liefeng and Fox, Dieter},\n",
      " booktitle = {Proceedings of the 29th International Conference on Machine Learning (ICML-12)},\n",
      " notes = {Empty},\n",
      " pages = {1671--1678},\n",
      " title = {A Joint Model of Language and Perception for Grounded Attribute Learning},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{Mavridis2006,\n",
      " abstract = {Empty},\n",
      " annote = {interesting contrast on this one is the bidirectionality\n",
      "does bidirectional exist in the others, or is it only in the external application.. is this an issue? },\n",
      " author = {Mavridis, Nikolaos and Roy, Deb},\n",
      " doi = {10.1109/IROS.2006.282210},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/mavridis_roy_iros_2006.pdf:pdf},\n",
      " isbn = {1-4244-0258-1},\n",
      " journal = {2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},\n",
      " month = {October},\n",
      " notes = {Empty},\n",
      " pages = {3--3},\n",
      " publisher = {IEEE},\n",
      " title = {{Grounded Situation Models: Where Words and Percepts Meet}},\n",
      " url = {#},\n",
      " year = {2006}\n",
      "}\n",
      "\n",
      "@inproceedings{mavridis2006grounded,\n",
      " abstract = {Empty},\n",
      " author = {Mavridis, Nikolaos and Roy, Deb},\n",
      " booktitle = {Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {4690--4697},\n",
      " summary = {Describes a grounded situation model which linked up linguistic data with experiential data of a robotic agent.  It is not clear what specific model of properties, if the properties are hand coded (i.e. how does it know what shades are \"blue\") or how the linguistic details hook up the semantic details (was the link between the color label \"blue\" and the color value \"blue\" hand coded?).},\n",
      " title = {Grounded situation models for robots: Where words and percepts meet},\n",
      " url = {#},\n",
      " year = {2006}\n",
      "}\n",
      "\n",
      "@inproceedings{MavridisRoy2006,\n",
      " abstract = {Empty},\n",
      " author = {Mavridis, Nikolaos and Roy, Deb},\n",
      " booktitle = {Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {4690--4697},\n",
      " summary = {Describes a grounded situation model which linked up linguistic data with experiential data of a robotic agent.  It is not clear what specific model of properties, if the properties are hand coded (i.e. how does it know what shades are \"blue\") or how the linguistic details hook up the semantic details (was the link between the color label \"blue\" and the color value \"blue\" hand coded?).},\n",
      " title = {Grounded situation models for robots: Where words and percepts meet},\n",
      " url = {#},\n",
      " year = {2006}\n",
      "}\n",
      "\n",
      "@article{mcmahan2015bayesian,\n",
      " abstract = {Empty},\n",
      " author = {McMahan, Brian and Stone, Matthew},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " pages = {103--115},\n",
      " title = {A Bayesian Model of Grounded Color Semantics},\n",
      " url = {#},\n",
      " volume = {3},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@unpublished{mcmahan:2014,\n",
      " abstract = {Empty},\n",
      " author = {Brian McMahan and Matthew Stone},\n",
      " note = {Manuscript, Rutgers University},\n",
      " notes = {Empty},\n",
      " title = {A {Bayesian} approach to grounded color semantics},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{mcmahanstone:color,\n",
      " abstract = {Empty},\n",
      " author = {Brian McMahan and Matthew Stone},\n",
      " journal = {Transactions of the ACL},\n",
      " notes = {Empty},\n",
      " title = {A Bayesian Model of Grounded Color Semantics},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@misc{meo2014generating,\n",
      " abstract = {Empty},\n",
      " author = {Meo, Timothy and McMahan, Brian and Stone, Matthew},\n",
      " notes = {Empty},\n",
      " publisher = {SEMDIAL},\n",
      " title = {Generating and resolving vague color references},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@inproceedings{meo:2014,\n",
      " abstract = {Empty},\n",
      " author = {Meo, Timothy and McMahan, Brian and Stone, Matthew},\n",
      " booktitle = {SemDial 2014: Proceedings of the 18th Workshop on the Semantics and Pragmatics of Dialogue},\n",
      " notes = {Empty},\n",
      " title = {Generating and Resolving Vague Color References},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{meomcmahanstone:color,\n",
      " abstract = {Empty},\n",
      " author = {Timothy Meo and Brian McMahan and Matthew Stone},\n",
      " journal = {SemDial},\n",
      " notes = {Empty},\n",
      " pages = {107--114},\n",
      " title = {Generating and Resolving Vague Color Reference},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{metropolis1953equation,\n",
      " abstract = {Empty},\n",
      " author = {Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},\n",
      " journal = {The journal of chemical physics},\n",
      " notes = {Empty},\n",
      " number = {6},\n",
      " pages = {1087--1092},\n",
      " publisher = {AIP Publishing},\n",
      " title = {Equation of state calculations by fast computing machines},\n",
      " url = {#},\n",
      " volume = {21},\n",
      " year = {1953}\n",
      "}\n",
      "\n",
      "@inproceedings{mikolov2010recurrent,\n",
      " abstract = {A new recurrent neural network based language model (RNN\n",
      "LM) with applications to speech recognition is presented. Results\n",
      "indicate that it is possible to obtain around 50% reduction\n",
      "of perplexity by using mixture of several RNN LMs, compared\n",
      "to a state of the art backoff language model. Speech recognition\n",
      "experiments show around 18% reduction of word error rate on\n",
      "the Wall Street Journal task when comparing models trained on\n",
      "the same amount of data, and around 5% on the much harder\n",
      "NIST RT05 task, even when the backoff model is trained on\n",
      "much more data than the RNN LM. We provide ample empirical\n",
      "evidence to suggest that connectionist language models are\n",
      "superior to standard n-gram techniques, except their high computational\n",
      "(training) complexity},\n",
      " author = {Mikolov, Tomas and Karafiát, Martin and Burget, Lukas and Cernock{ỳ}, Jan and Khudanpur, Sanjeev},\n",
      " booktitle = {INTERSPEECH},\n",
      " notes = {Empty},\n",
      " pages = {3},\n",
      " title = {Recurrent neural network based language model.},\n",
      " url = {#},\n",
      " volume = {2},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@inproceedings{mikolov2011empirical,\n",
      " abstract = {Empty},\n",
      " author = {Mikolov, Tomas and Deoras, Anoop and Kombrink, Stefan and Burget, Lukas and Cernock{ỳ}, Jan},\n",
      " booktitle = {INTERSPEECH},\n",
      " notes = {Empty},\n",
      " number = {s 1},\n",
      " pages = {605--608},\n",
      " title = {Empirical Evaluation and Combination of Advanced Language Modeling Techniques.},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@inproceedings{mikolov2011strategies,\n",
      " abstract = {Empty},\n",
      " author = {Mikolov, Tomá{š} and Deoras, Anoop and Povey, Daniel and Burget, Luká{š} and {Č}ernock{ỳ}, Jan},\n",
      " booktitle = {Automatic Speech Recognition and Understanding (ASRU), 2011 IEEE Workshop on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {196--201},\n",
      " title = {Strategies for training large scale neural network language models},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@inproceedings{mikolov2012context,\n",
      " abstract = {Empty},\n",
      " author = {Mikolov, Tomas and Zweig, Geoffrey},\n",
      " booktitle = {SLT},\n",
      " notes = {Empty},\n",
      " pages = {234--239},\n",
      " title = {Context dependent recurrent neural network language model.},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@inproceedings{mikolov2013distributed,\n",
      " abstract = {Empty},\n",
      " author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},\n",
      " booktitle = {Advances in neural information processing systems},\n",
      " notes = {Empty},\n",
      " pages = {3111--3119},\n",
      " title = {Distributed representations of words and phrases and their compositionality},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@inproceedings{mnih2007three,\n",
      " abstract = {Empty},\n",
      " author = {Mnih, Andriy and Hinton, Geoffrey},\n",
      " booktitle = {Proceedings of the 24th international conference on Machine learning},\n",
      " notes = {Empty},\n",
      " organization = {ACM},\n",
      " pages = {641--648},\n",
      " title = {Three new graphical models for statistical language modelling},\n",
      " url = {#},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{mnih2012fast,\n",
      " abstract = {In spite of their superior performance, neural\n",
      "probabilistic language models (NPLMs) remain\n",
      "far less widely used than n-gram models\n",
      "due to their notoriously long training\n",
      "times, which are measured in weeks even for\n",
      "moderately-sized datasets. Training NPLMs\n",
      "is computationally expensive because they\n",
      "are explicitly normalized, which leads to having\n",
      "to consider all words in the vocabulary\n",
      "when computing the log-likelihood gradients.\n",
      "We propose a fast and simple algorithm for\n",
      "training NPLMs based on noise-contrastive\n",
      "estimation, a newly introduced procedure for\n",
      "estimating unnormalized continuous distributions.\n",
      "We investigate the behaviour of the\n",
      "algorithm on the Penn Treebank corpus and\n",
      "show that it reduces the training times by\n",
      "more than an order of magnitude without affecting\n",
      "the quality of the resulting models.\n",
      "The algorithm is also more efficient and much\n",
      "more stable than importance sampling because\n",
      "it requires far fewer noise samples to\n",
      "perform well.\n",
      "We demonstrate the scalability of the proposed\n",
      "approach by training several neural\n",
      "language models on a 47M-word corpus with\n",
      "a 80K-word vocabulary, obtaining state-ofthe-art\n",
      "results on the Microsoft Research\n",
      "Sentence Completion Challenge dataset.},\n",
      " author = {Mnih, Andriy and Teh, Yee Whye},\n",
      " journal = {arXiv preprint arXiv:1206.6426},\n",
      " notes = {optimizing the training NNLM models},\n",
      " title = {A fast and simple algorithm for training neural probabilistic language models},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@inproceedings{mnih2014recurrent,\n",
      " abstract = {Applying convolutional neural networks to large images is computationally expensive\n",
      "because the amount of computation scales linearly with the number of\n",
      "image pixels. We present a novel recurrent neural network model that is capable\n",
      "of extracting information from an image or video by adaptively selecting\n",
      "a sequence of regions or locations and only processing the selected regions at\n",
      "high resolution. Like convolutional neural networks, the proposed model has a\n",
      "degree of translation invariance built-in, but the amount of computation it performs\n",
      "can be controlled independently of the input image size. While the model\n",
      "is non-differentiable, it can be trained using reinforcement learning methods to\n",
      "learn task-specific policies. We evaluate our model on several image classification\n",
      "tasks, where it significantly outperforms a convolutional neural network baseline\n",
      "on cluttered images, and on a dynamic visual control problem, where it learns to\n",
      "track a simple object without an explicit training signal for doing so.},\n",
      " author = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and others},\n",
      " booktitle = {Advances in Neural Information Processing Systems},\n",
      " notes = {Empty},\n",
      " pages = {2204--2212},\n",
      " title = {Recurrent models of visual attention},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@inproceedings{msr2012completionchallenge,\n",
      " abstract = {<p>In this paper, we describe a new, publicly available corpus intended to\n",
      "stimulate research into language modeling techniques which are sensitive to\n",
      "overall sentence coherence. The task uses the Scholastic Aptitude Test’s sentence\n",
      "completion format. The test set consists of 1040 sentences, each of which is\n",
      "missing a content word. The goal is to select the correct replacement from\n",
      "amongst five alternates. In general, all of the options are syntactically valid,\n",
      "and reasonable with respect to local N-gram statistics. The set was generated by\n",
      "using an N-gram language model to generate a long list of likely words, given the\n",
      "immediate context. These options were then hand-groomed, to identify four decoys\n",
      "which are globally incoherent, yet syntactically correct. To ensure the right to\n",
      "public distribution, all the data is derived from out-of-copyright materials from\n",
      "Project Gutenberg. The test sentences were derived from five of Conan Doyle’s\n",
      "Sherlock Holmes novels, and we provide a large set of Nineteenth and early\n",
      "Twentieth Century texts as training material.</p>},\n",
      " author = {Geoffrey Zweig and Chris J.C. Burges},\n",
      " booktitle = {Workshop on the Future of Language Modeling for HLT, NAACL-HLT 2012},\n",
      " month = {June},\n",
      " notes = {Empty},\n",
      " publisher = {ACL/SIGPARSE},\n",
      " title = {A Challenge Set for Advancing Language Modeling},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@inproceeds{msrcaptions,\n",
      " abstract = {Empty},\n",
      " author = {Fang, Hao and Gupta, Saurabh and Iandola, Forrest and Srivastava, Rupesh and Deng, Li and Dollár, Piotr and Gao, Jianfeng and He, Xiaodong and Mitchell, Margaret and Platt, John and others},\n",
      " booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n",
      " notes = {Empty},\n",
      " pages = {},\n",
      " title = {From captions to visual concepts and back},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@online{Munroe:ColorData,\n",
      " abstract = {Empty},\n",
      " author = {Munroe, Randall},\n",
      " notes = {Empty},\n",
      " title = {Color Survey Results},\n",
      " url = {#},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@article{neu2012apprenticeship,\n",
      " abstract = {In this paper we propose a novel gradient algorithm\n",
      "to learn a policy from an expert’s\n",
      "observed behavior assuming that the expert\n",
      "behaves optimally with respect to some unknown\n",
      "reward function of a Markovian Decision\n",
      "Problem. The algorithm’s aim is to\n",
      "find a reward function such that the resulting\n",
      "optimal policy matches well the expert’s observed\n",
      "behavior. The main difficulty is that\n",
      "the mapping from the parameters to policies\n",
      "is both nonsmooth and highly redundant.\n",
      "Resorting to subdifferentials solves the\n",
      "first difficulty, while the second one is overcome\n",
      "by computing natural gradients. We\n",
      "tested the proposed method in two artificial\n",
      "domains and found it to be more reliable and\n",
      "efficient than some previous methods.},\n",
      " author = {Neu, Gergely and Szepesvári, Csaba},\n",
      " journal = {arXiv preprint arXiv:1206.5264},\n",
      " notes = {Empty},\n",
      " title = {Apprenticeship learning using inverse reinforcement learning and gradient methods},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@inproceedings{ng2000algorithms,\n",
      " abstract = {This paper addresses the problem of inverse reinforcement learning (IRL) in Markov decision processes, that is the problem of extracting a reward function given observed, optimal behavior.  IRL may be useful for apprenticeship learning to acquire skilled behavior, and for ascertaining the reward function being optimized by a natural system.  We first characterize the set of all reward functions for which a given policy is optimal.  We then derive three algorithms for IRL.  The first two deal with the case where the entire policy is known; we handle tabulated reward functions on a finite state space and linear functional approximation of the reward function over a potentially infinite state space.  The third algorithm deals with the more realistic case in which the policy is known only through a finite set of observed trajectories.  In all cases, a key issue is degeneracy---the existence of a large set of reward functions for which the observed policy is optimal.  To remove degeneracy, we suggest that some natural heuristics that attempt to pick a reward function that maximally differentiates the observed policy from other, sub-optimal policy.  This results in an efficiently solvable linear programming formulation of the IRL problem.  We demonstrate our algorithms on simple discrete/finite and continuous/infinite problems},\n",
      " author = {Ng, Andrew Y and Russell, Stuart J and others},\n",
      " booktitle = {ICML},\n",
      " notes = {Empty},\n",
      " pages = {663--670},\n",
      " title = {Algorithms for inverse reinforcement learning.},\n",
      " url = {#},\n",
      " year = {2000}\n",
      "}\n",
      "\n",
      "@inproceedings{Oates:2003:LWM,\n",
      " abstract = {Empty},\n",
      " author = {Oates, Tim},\n",
      " booktitle = {Proceedings of the HLT-NAACL 2003 Workshop on Learning Word Meaning from Non-Linguistic Data},\n",
      " editor = {Regina Barzilay, Ehud Reiter and Jeffrey Mark Siskind},\n",
      " notes = {Empty},\n",
      " pages = {62--69},\n",
      " title = {Grounding Word Meanings in Sensor Data: Dealing with Referential Uncertainty},\n",
      " url = {#},\n",
      " year = {2003}\n",
      "}\n",
      "\n",
      "@article{omitted,\n",
      " abstract = {Empty},\n",
      " author = {Anonymous Anonymous},\n",
      " journal = {Anonymous},\n",
      " notes = {Empty},\n",
      " title = {Anonymous},\n",
      " url = {#},\n",
      " year = {xxxx}\n",
      "}\n",
      "\n",
      "@article{Ordonez2013,\n",
      " abstract = {Empty},\n",
      " author = {Ordonez, Vicente and Deng, Jia and Choi, Yejin and Berg, Alexander C. and Berg, Tamara L.},\n",
      " doi = {10.1109/ICCV.2013.344},\n",
      " file = {:C$\\backslash$:/research/papers/computer vision/berg_entrylevel.pdf:pdf},\n",
      " isbn = {978-1-4799-2840-8},\n",
      " journal = {2013 IEEE International Conference on Computer Vision},\n",
      " month = {December},\n",
      " notes = {Empty},\n",
      " pages = {2768--2775},\n",
      " publisher = {Ieee},\n",
      " title = {{From Large Scale Image Categorization to Entry-Level Categories}},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{pennington2014glove,\n",
      " abstract = {Empty},\n",
      " author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},\n",
      " journal = {Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014)},\n",
      " notes = {Empty},\n",
      " pages = {1532--1543},\n",
      " title = {Glove: Global vectors for word representation},\n",
      " url = {#},\n",
      " volume = {12},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{persaud2016dynamics,\n",
      " abstract = {Empty},\n",
      " author = {Persaud, Kimele and Hemmer, Pernille},\n",
      " journal = {Cognitive psychology},\n",
      " notes = {Empty},\n",
      " pages = {1--21},\n",
      " publisher = {Elsevier},\n",
      " title = {The dynamics of fidelity over the time course of long-term memory},\n",
      " url = {#},\n",
      " volume = {88},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{quine1960,\n",
      " abstract = {Empty},\n",
      " author = {Quine, MVO},\n",
      " notes = {Empty},\n",
      " publisher = {MIT Press},\n",
      " title = {Word and object},\n",
      " url = {#},\n",
      " year = {1960}\n",
      "}\n",
      "\n",
      "@article{ramachandran2007bayesian,\n",
      " abstract = {Inverse Reinforcement Learning (IRL) is the problem\n",
      "of learning the reward function underlying a\n",
      "Markov Decision Process given the dynamics of\n",
      "the system and the behaviour of an expert. IRL\n",
      "is motivated by situations where knowledge of the\n",
      "rewards is a goal by itself (as in preference elicitation)\n",
      "and by the task of apprenticeship learning\n",
      "(learning policies from an expert). In this paper\n",
      "we show how to combine prior knowledge and evidence\n",
      "from the expert’s actions to derive a probability\n",
      "distribution over the space of reward functions.\n",
      "We present efficient algorithms that find solutions\n",
      "for the reward learning and apprenticeship learning\n",
      "tasks that generalize well over these distributions.\n",
      "Experimental results show strong improvement\n",
      "for our methods over previous heuristic-based\n",
      "approaches},\n",
      " author = {Ramachandran, Deepak and Amir, Eyal},\n",
      " journal = {Urbana},\n",
      " notes = {Empty},\n",
      " pages = {61801},\n",
      " title = {Bayesian inverse reinforcement learning},\n",
      " url = {#},\n",
      " volume = {51},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{ratia2012performance,\n",
      " abstract = {Inverse reinforcement learning (IRL) addresses the problem\n",
      "of recovering a task description given a demonstration of the optimal\n",
      "policy used to solve such a task. The optimal policy is usually provided\n",
      "by an expert or teacher, making IRL specially suitable for the problem\n",
      "of apprenticeship learning. The task description is encoded in the form\n",
      "of a reward function of a Markov decision process (MDP). Several algorithms\n",
      "have been proposed to find the reward function corresponding to\n",
      "a set of demonstrations. One of the algorithms that has provided best\n",
      "results in different applications is a gradient method to optimize a policy\n",
      "squared error criterion. On a parallel line of research, other authors have\n",
      "presented recently a gradient approximation of the maximum likelihood\n",
      "estimate of the reward signal. In general, both approaches approximate\n",
      "the gradient estimate and the criteria at different stages to make the\n",
      "algorithm tractable and efficient. In this work, we provide a detailed\n",
      "description of the different methods to highlight differences in terms of\n",
      "reward estimation, policy similarity and computational costs. We also\n",
      "provide experimental results to evaluate the differences in performance\n",
      "of the methods.},\n",
      " author = {Ratia, Héctor and Montesano, Luis and Martinez-Cantin, Ruben},\n",
      " journal = {arXiv preprint arXiv:1202.1558},\n",
      " notes = {Empty},\n",
      " title = {On the Performance of Maximum Likelihood Inverse Reinforcement Learning},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{regier2007color,\n",
      " abstract = {Empty},\n",
      " author = {Regier, Terry and Kay, Paul and Khetarpal, Naveen},\n",
      " journal = {Proceedings of the National Academy of Sciences},\n",
      " notes = {Empty},\n",
      " number = {4},\n",
      " pages = {1436--1441},\n",
      " publisher = {National Acad Sciences},\n",
      " title = {Color naming reflects optimal partitions of color space},\n",
      " url = {#},\n",
      " volume = {104},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{regier:pnas05,\n",
      " abstract = {Empty},\n",
      " author = {Terry Regier and Paul Kay and Richard S. Cook},\n",
      " journal = {Proceedings of the National Academy of Sciences},\n",
      " notes = {Empty},\n",
      " pages = {8386--8391},\n",
      " title = {Focal colors are universal after all},\n",
      " url = {#},\n",
      " volume = {102},\n",
      " year = {2005}\n",
      "}\n",
      "\n",
      "@article{regier:pnas07,\n",
      " abstract = {Empty},\n",
      " author = {Terry Regier and Paul Kay and Naveen Khetarpal},\n",
      " journal = {Proceedings of the National Academy of Sciences},\n",
      " notes = {Empty},\n",
      " pages = {1436--1441},\n",
      " title = {Color naming reflects optimal partitions of color space},\n",
      " url = {#},\n",
      " volume = {104},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{regier:snow,\n",
      " abstract = {Empty},\n",
      " author = {Regier, Terry AND Carstensen, Alexandra AND Kemp, Charles},\n",
      " journal = {PLOS ONE},\n",
      " month = {04},\n",
      " notes = {Empty},\n",
      " pages = {1-17},\n",
      " publisher = {Public Library of Science},\n",
      " title = {Languages Support Efficient Communication about the Environment: Words for Snow Revisited},\n",
      " url = {#},\n",
      " volume = {11},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{Regneri2013,\n",
      " abstract = {Empty},\n",
      " author = {Regneri, Michaela and Rohrbach, Marcus and Wetzel, Dominikus and Thater, Stefan and Schiele, Bernt and Pinkal, Manfred},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/regneri_etal_tacl_2013_action_descs_videos.pdf:pdf},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " pages = {25--36},\n",
      " title = {Grounding action descriptions in videos},\n",
      " url = {#},\n",
      " volume = {1},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{reiter2005choosing,\n",
      " abstract = {Empty},\n",
      " author = {Reiter, Ehud and Sripada, Somayajulu and Hunter, Jim and Yu, Jin and Davy, Ian},\n",
      " journal = {Artificial Intelligence},\n",
      " notes = {Empty},\n",
      " number = {1-2},\n",
      " pages = {137--169},\n",
      " publisher = {Elsevier},\n",
      " title = {Choosing words in computer-generated weather forecasts},\n",
      " url = {#},\n",
      " volume = {167},\n",
      " year = {2005}\n",
      "}\n",
      "\n",
      "@inproceedings{resnik1992probabilistic,\n",
      " abstract = {Empty},\n",
      " author = {Resnik, Philip},\n",
      " booktitle = {Proceedings of the 14th conference on Computational linguistics-Volume 2},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {418--424},\n",
      " title = {Probabilistic tree-adjoining grammar as a framework for statistical natural language processing},\n",
      " url = {#},\n",
      " year = {1992}\n",
      "}\n",
      "\n",
      "@article{rooth1992theory,\n",
      " abstract = {Empty},\n",
      " author = {Rooth, Mats},\n",
      " journal = {Natural language semantics},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {75--116},\n",
      " publisher = {Kluwer Academic Publishers},\n",
      " title = {A theory of focus interpretation},\n",
      " url = {#},\n",
      " volume = {1},\n",
      " year = {1992}\n",
      "}\n",
      "\n",
      "@article{Roy05,\n",
      " abstract = {Empty},\n",
      " author = {Deb Roy},\n",
      " bibsource = {DBLP, http://dblp.uni-trier.de},\n",
      " ee = {http://dx.doi.org/10.1016/j.artint.2005.04.007},\n",
      " journal = {Artififical Intelligence},\n",
      " notes = {Empty},\n",
      " number = {1-2},\n",
      " pages = {170--205},\n",
      " summary = {This paper describes a semiotic schema - a common sensory-motor representation for verbs, adjectives, and nouns.  It also defines grounding as relating beliefs to external physical objects.},\n",
      " title = {Semiotic schemas: A framework for grounding language in\n",
      "action and perception},\n",
      " url = {#},\n",
      " volume = {167},\n",
      " year = {2005}\n",
      "}\n",
      "\n",
      "@article{roy2002learning,\n",
      " abstract = {Empty},\n",
      " author = {Roy, Deb K. and Pentland, Alex P.},\n",
      " doi = {10.1207/s15516709cog2601_4},\n",
      " issn = {1551-6709},\n",
      " journal = {Cognitive Science},\n",
      " keywords = {Language acquisition, Cross-modal, Sensor grounded, Learning, Computational model},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {113--146},\n",
      " publisher = {Lawrence Erlbaum Associates, Inc.},\n",
      " title = {Learning words from sights and sounds: a computational model},\n",
      " url = {#},\n",
      " volume = {26},\n",
      " year = {2002}\n",
      "}\n",
      "\n",
      "@article{RoyR05,\n",
      " abstract = {Empty},\n",
      " author = {Deb Roy and\n",
      "Ehud Reiter},\n",
      " bibsource = {DBLP, http://dblp.uni-trier.de},\n",
      " ee = {http://dx.doi.org/10.1016/j.artint.2005.06.002},\n",
      " journal = {Artifical Intelligence},\n",
      " notes = {Empty},\n",
      " number = {1-2},\n",
      " pages = {1-12},\n",
      " summary = {Describes the challenges and difficulties that face situated language. It highlights color terms specifically citing issues like domain-specific uses (red hair, red wine, or red car), when it denotes a specific property (green banana), when to use more specific words (red vs crimson), and how it applies to parts of an object (red car vs red car with silver trim).  It also makes the point that linguistic terms need to be grounded in perceptual categories. },\n",
      " title = {Connecting language to the world},\n",
      " url = {#},\n",
      " volume = {167},\n",
      " year = {2005}\n",
      "}\n",
      "\n",
      "@misc{rrnlm:github,\n",
      " abstract = {Empty},\n",
      " author = {YANDEX},\n",
      " notes = {Empty},\n",
      " title = {Faster RNNLM Github Repo},\n",
      " url = {#},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@inproceedings{salama2016multimodal,\n",
      " abstract = {Dependency parsing is a popular approach for syntactic analysis of natural language utterances. It concerns building a dependency tree of the linguistic input relying only on a model of syntactic regularities. The cognitive process of human language processing, however, has also access to other sources of knowledge, like visual clues that can be used to improve language understanding.\n",
      "In this paper, we approach integrating visual context and linguistic information to improve the reliability of dependency parsing. To achieve this goal, we modify a state-of-the-art dependency parser to make it accept visual information as extra features in addition to the original linguistic input. All these inputs (features) are considered in the learning process of the trained model. Experiments have been carried out to investigate the contribution of this additional multimodal information on ambiguity resolution and parsing quality.},\n",
      " author = {Salama, Amr Rekaby and Menzel, Wolfgang},\n",
      " booktitle = {International Conference on Advanced Intelligent Systems and Informatics},\n",
      " notes = {Empty},\n",
      " organization = {Springer},\n",
      " pages = {22--31},\n",
      " title = {Multimodal Graph-Based Dependency Parsing of Natural Language},\n",
      " url = {http://link.springer.com/chapter/10.1007/978-3-319-48308-5_3},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{Saleh2013,\n",
      " abstract = {Empty},\n",
      " author = {Saleh, Babak and Farhadi, Ali and Elgammal, Ahmed},\n",
      " doi = {10.1109/CVPR.2013.107},\n",
      " file = {:C$\\backslash$:/research/papers/computer vision/babak_anomaly_detection_2013.pdf:pdf},\n",
      " isbn = {978-0-7695-4989-7},\n",
      " journal = {2013 IEEE Conference on Computer Vision and Pattern Recognition},\n",
      " mendeley-groups = {computer vision},\n",
      " month = {June},\n",
      " notes = {Empty},\n",
      " pages = {787--794},\n",
      " publisher = {Ieee},\n",
      " title = {{Object-Centric Anomaly Detection by Attribute-Based Reasoning}},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{schlangen2015resolving,\n",
      " abstract = {Empty},\n",
      " author = {Schlangen, David and Zarriess, Sina and Kennington, Casey},\n",
      " journal = {arXiv preprint arXiv:1510.02125},\n",
      " notes = {Empty},\n",
      " title = {Resolving References to Objects in Photographs using the Words-As-Classifiers Model},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@article{schloss:colorvalence,\n",
      " abstract = {Empty},\n",
      " author = {Palmer, Stephen E and Schloss, Karen B},\n",
      " journal = {Proceedings of the National Academy of Sciences},\n",
      " notes = {Empty},\n",
      " number = {19},\n",
      " pages = {8877--8882},\n",
      " publisher = {National Acad Sciences},\n",
      " title = {An ecological valence theory of human color preference},\n",
      " url = {#},\n",
      " volume = {107},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@inproceedings{schmidt2009tall,\n",
      " abstract = {Empty},\n",
      " author = {Schmidt, Lauren A and Goodman, Noah D and Barner, David and Tenenbaum, Joshua B},\n",
      " booktitle = {Proceedings of the 31st annual conference of the cognitive science society},\n",
      " notes = {Empty},\n",
      " organization = {Citeseer},\n",
      " pages = {2759--2764},\n",
      " title = {How tall is tall? compositionality, statistics, and gradable adjectives},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@article{sedivy1999achieving,\n",
      " abstract = {Empty},\n",
      " author = {Sedivy, Julie C and Tanenhaus, Michael K and Chambers, Craig G and Carlson, Gregory N},\n",
      " journal = {Cognition},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {109--147},\n",
      " publisher = {Elsevier},\n",
      " title = {Achieving incremental semantic interpretation through contextual representation},\n",
      " url = {#},\n",
      " volume = {71},\n",
      " year = {1999}\n",
      "}\n",
      "\n",
      "@inproceedings{Silberer2013,\n",
      " abstract = {Empty},\n",
      " author = {Silberer, Carina and Ferrari, Vittorio and Lapata, Mirella},\n",
      " booktitle = {ACL (1)},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/distributional semantics/silberer_ferrari_lapata_ds_with_visual_attr.pdf:pdf},\n",
      " notes = {Empty},\n",
      " pages = {572--582},\n",
      " title = {{Models of Semantic Representation with Visual Attributes}},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@inproceedings{silberer2013models,\n",
      " abstract = {Empty},\n",
      " author = {Silberer, Carina and Ferrari, Vittorio and Lapata, Mirella},\n",
      " booktitle = {ACL (1)},\n",
      " notes = {Empty},\n",
      " pages = {572--582},\n",
      " title = {Models of Semantic Representation with Visual Attributes.},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{simon1956rational,\n",
      " abstract = {Empty},\n",
      " author = {Simon, Herbert A},\n",
      " journal = {Psychological review},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {129},\n",
      " publisher = {American Psychological Association},\n",
      " title = {Rational choice and the structure of the environment.},\n",
      " url = {#},\n",
      " volume = {63},\n",
      " year = {1956}\n",
      "}\n",
      "\n",
      "@article{simsexploring,\n",
      " abstract = {Empty},\n",
      " author = {Sims, Chris R and Ma, Zheng and Allred, Sarah R and Lerch, Rachel A and Flombaum, Jonathan I},\n",
      " notes = {Empty},\n",
      " title = {Exploring the Cost Function in Color Perception and Memory: An Information-Theoretic Model of Categorical Effects in Color Matching},\n",
      " url = {#},\n",
      " year = {Empty}\n",
      "}\n",
      "\n",
      "@inproceedings{smith:nips13,\n",
      " abstract = {Empty},\n",
      " author = {Nathaniel J. Smith and Noah D. Goodman and Michael C. Frank},\n",
      " booktitle = {Advances in Neural Information Processing Systems 26},\n",
      " notes = {Empty},\n",
      " pages = {3039--3047},\n",
      " title = {Learning and using language via recursive pragmatic reasoning about other agents},\n",
      " url = {#},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{socher2010learning,\n",
      " abstract = {Empty},\n",
      " author = {Socher, Richard and Manning, Christopher D and Ng, Andrew Y},\n",
      " journal = {Proceedings of the NIPS-2010 Deep Learning and Unsupervised Feature Learning Workshop},\n",
      " notes = {Empty},\n",
      " pages = {1--9},\n",
      " title = {Learning continuous phrase representations and syntactic parsing with recursive neural networks},\n",
      " url = {#},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@inproceedings{socher2011parsing,\n",
      " abstract = {Empty},\n",
      " author = {Socher, Richard and Lin, Cliff C. and Ng, Andrew and Manning, Chris},\n",
      " booktitle = {Proceedings of the 28th International Conference on Machine Learning (ICML-11)},\n",
      " notes = {Empty},\n",
      " pages = {129--136},\n",
      " summary = {This paper describes an approach which takes annotate natural scenes and text and attempts to find recursive relations that describe the two. The theory is that a scene description's hierarchical structure reflects the hierarchical conceptual organization of the scene},\n",
      " title = {Parsing natural scenes and natural language with recursive neural networks},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{socher2014grounded,\n",
      " abstract = {Empty},\n",
      " author = {Socher, Richard and Karpathy, Andrej and Le, Quoc V and Manning, Christopher D and Ng, Andrew Y},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " pages = {207--218},\n",
      " title = {Grounded compositional semantics for finding and describing images with sentences},\n",
      " url = {#},\n",
      " volume = {2},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{steels-belpaeme-cpgcl:2005,\n",
      " abstract = {Empty},\n",
      " author = {Luc Steels and Tony Belpaeme},\n",
      " journal = {Behavioral and Brain Sciences},\n",
      " notes = {Empty},\n",
      " number = {4},\n",
      " pages = {469--529},\n",
      " title = {Coordinating Perceptually Grounded Categories through Language. {A} Case Study for Colour},\n",
      " url = {#},\n",
      " volume = {28},\n",
      " year = {2005}\n",
      "}\n",
      "\n",
      "@inproceedings{stickles2014relation,\n",
      " abstract = {Empty},\n",
      " author = {Stickles, Elise and Regier, Terry},\n",
      " booktitle = {CogSci},\n",
      " notes = {Empty},\n",
      " title = {The relation of color naming and the environment.},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@inproceedings{stone1997sentence,\n",
      " abstract = {Empty},\n",
      " author = {Stone, Matthew and Doran, Christine},\n",
      " booktitle = {Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " organization = {Association for Computational Linguistics},\n",
      " pages = {198--205},\n",
      " title = {Sentence planning as description using tree adjoining grammar},\n",
      " url = {#},\n",
      " year = {1997}\n",
      "}\n",
      "\n",
      "@article{tai2015improved,\n",
      " abstract = {Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).},\n",
      " author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D},\n",
      " journal = {arXiv preprint arXiv:1503.00075},\n",
      " notes = {Empty},\n",
      " title = {Improved semantic representations from tree-structured long short-term memory networks},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@inproceedings{Tellex2009,\n",
      " abstract = {Empty},\n",
      " author = {Tellex, Stefanie and Roy, Deb},\n",
      " booktitle = {Proceedings of the 2009 international conference on Multimodal interfaces},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/tellex_roy_spatial_prepositions_2009.pdf:pdf},\n",
      " isbn = {9781605587721},\n",
      " keywords = {spatial language,video retrieval},\n",
      " notes = {Empty},\n",
      " organization = {ACM},\n",
      " pages = {253--260},\n",
      " title = {Grounding spatial prepositions for video search},\n",
      " url = {#},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@phdthesis{tellex2010natural,\n",
      " abstract = {Empty},\n",
      " author = {Tellex, Stefanie},\n",
      " notes = {Empty},\n",
      " school = {Massachusetts Institute of Technology},\n",
      " title = {Natural language and spatial reasoning},\n",
      " url = {#},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@article{Tellex2011,\n",
      " abstract = {Empty},\n",
      " author = {Tellex, Stefanie and Kollar, Thomas and Dickerson, Steven and Walter, Matthew R and Banerjee, Ashis Gopal and Teller, Seth J and Roy, Nicholas},\n",
      " booktitle = {AAAI},\n",
      " notes = {Empty},\n",
      " title = {Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation.},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{Tellex2011a,\n",
      " abstract = {Empty},\n",
      " annote = {Tellex factors the sentence into  a single structure and then assumes each constituent of that structure has a fixed grounding (path and object) and that each of these things is independent.\n",
      "This works well for descriptions describing actions that necessarily involve the environment.\n",
      "Does this have any downsides for general grounded semantics?  How should this fit into the larger picture? },\n",
      " author = {Tellex, Stefanie and Kollar, Thomas and Dickerson, Steven},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/tellex_etal_2011.pdf:pdf},\n",
      " journal = {AI magazine},\n",
      " notes = {Empty},\n",
      " title = {{Approaching the symbol grounding problem with probabilistic graphical models}},\n",
      " url = {#},\n",
      " year = {2011}\n",
      "}\n",
      "\n",
      "@article{Tellex2013,\n",
      " abstract = {Empty},\n",
      " author = {Tellex, Stefanie and Thaker, Pratiksha and Joseph, Joshua and Roy, Nicholas},\n",
      " doi = {10.1007/s10994-013-5383-2},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/unaligned_data_tellex_etal_13.pdf:pdf},\n",
      " issn = {0885-6125},\n",
      " journal = {Machine Learning},\n",
      " keywords = {language,machine learning,probabilistic graphical,robotics},\n",
      " month = {May},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {151--167},\n",
      " title = {{Learning perceptually grounded word meanings from unaligned parallel data}},\n",
      " url = {#},\n",
      " volume = {94},\n",
      " year = {2013}\n",
      "}\n",
      "\n",
      "@article{tenenbaum1998mapping,\n",
      " abstract = {Empty},\n",
      " author = {Tenenbaum, Joshua B},\n",
      " journal = {Advances in neural information processing systems},\n",
      " notes = {Empty},\n",
      " pages = {682--688},\n",
      " publisher = {MORGAN KAUFMANN PUBLISHERS},\n",
      " title = {Mapping a manifold of perceptual observations},\n",
      " url = {#},\n",
      " year = {1998}\n",
      "}\n",
      "\n",
      "@incollection{thomason:intentions,\n",
      " abstract = {Empty},\n",
      " address = {Cambridge, MA},\n",
      " author = {Richmond H. Thomason},\n",
      " booktitle = {Intentions in Communication},\n",
      " editor = {Philip R. Cohen and Jerry Morgan and Martha E. Pollack},\n",
      " notes = {Empty},\n",
      " pages = {325--363},\n",
      " publisher = {{MIT} Press},\n",
      " title = {Accommodation, meaning and implicature},\n",
      " url = {#},\n",
      " year = {1990}\n",
      "}\n",
      "\n",
      "@article{Thompson2003,\n",
      " abstract = {Empty},\n",
      " author = {Thompson, CA and Mooney, RJ},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/thompson_mooney_jair_2003.pdf:pdf},\n",
      " journal = {Journal of Artificial Intelligence Research},\n",
      " notes = {Empty},\n",
      " pages = {1--44},\n",
      " title = {{Acquiring word-meaning mappings for natural language interfaces}},\n",
      " url = {#},\n",
      " volume = {18},\n",
      " year = {2003}\n",
      "}\n",
      "\n",
      "@incollection{travis:pragmatics,\n",
      " abstract = {Empty},\n",
      " author = {Charles Travis},\n",
      " booktitle = {A Companion to the Philosophy of Language},\n",
      " editor = {B. Hale and C. Wright},\n",
      " notes = {Empty},\n",
      " pages = {97--107},\n",
      " publisher = {Oxford},\n",
      " title = {Pragmatics},\n",
      " url = {#},\n",
      " year = {1997}\n",
      "}\n",
      "\n",
      "@book{tribus1961thermostatics,\n",
      " abstract = {Empty},\n",
      " author = {Tribus, Myron},\n",
      " notes = {Empty},\n",
      " publisher = {Center for Advanced Engineering Study, Massachusetts Institute of Technology},\n",
      " title = {Thermostatics and thermodynamics},\n",
      " url = {#},\n",
      " year = {1961}\n",
      "}\n",
      "\n",
      "@inproceedings{ullman2016pragmatics,\n",
      " abstract = {Empty},\n",
      " author = {Ullman, Tomer D and Xu, Yang and Goodman, Noah D},\n",
      " booktitle = {Proceedings of the 38th Annual Conference of the Cognitive Science Society},\n",
      " notes = {Empty},\n",
      " title = {The Pragmatics of Spatial Language},\n",
      " url = {#},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@incollection{van2004finetuning,\n",
      " abstract = {Empty},\n",
      " author = {Van Deemter, Kees},\n",
      " booktitle = {Natural Language Generation},\n",
      " notes = {Empty},\n",
      " pages = {31--40},\n",
      " publisher = {Springer},\n",
      " title = {Finetuning NLG through experiments with human subjects: the case of vague descriptions},\n",
      " url = {#},\n",
      " year = {2004}\n",
      "}\n",
      "\n",
      "@inproceedings{van2007applying,\n",
      " abstract = {Empty},\n",
      " author = {Van de Weijer, Joost and Schmid, Cordelia},\n",
      " booktitle = {Image Processing, 2007. ICIP 2007. IEEE International Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {III--493},\n",
      " title = {Applying color names to image description},\n",
      " url = {#},\n",
      " volume = {3},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@inproceedings{van2007learning,\n",
      " abstract = {Empty},\n",
      " author = {Van de Weijer, Joost and Schmid, Cordelia and Verbeek, Jakob},\n",
      " booktitle = {Computer Vision and Pattern Recognition, 2007. CVPR'07. IEEE Conference on},\n",
      " notes = {Empty},\n",
      " organization = {IEEE},\n",
      " pages = {1--8},\n",
      " title = {Learning color names from real-world images},\n",
      " url = {#},\n",
      " year = {2007}\n",
      "}\n",
      "\n",
      "@article{van2009utility,\n",
      " abstract = {Empty},\n",
      " author = {Van Deemter, Kees},\n",
      " journal = {Journal of Philosophical Logic},\n",
      " notes = {Empty},\n",
      " number = {6},\n",
      " pages = {607},\n",
      " publisher = {Springer},\n",
      " title = {Utility and language generation: The case of vagueness},\n",
      " url = {#},\n",
      " volume = {38},\n",
      " year = {2009}\n",
      "}\n",
      "\n",
      "@book{van2012not,\n",
      " abstract = {Empty},\n",
      " author = {Van Deemter, Kees},\n",
      " notes = {Empty},\n",
      " publisher = {Oxford University Press},\n",
      " title = {Not exactly: In praise of vagueness},\n",
      " url = {#},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{VanDeemter:2006,\n",
      " abstract = {Empty},\n",
      " address = {Cambridge, MA, USA},\n",
      " author = {van Deemter, Kees},\n",
      " issn = {0891-2017},\n",
      " issue_date = {June 2006},\n",
      " journal = {Comput. Linguist.},\n",
      " month = {June},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {195--222},\n",
      " publisher = {MIT Press},\n",
      " title = {Generating Referring Expressions That Involve Gradable Properties},\n",
      " url = {#},\n",
      " volume = {32},\n",
      " year = {2006}\n",
      "}\n",
      "\n",
      "@article{vandeemter:cl06,\n",
      " abstract = {Empty},\n",
      " author = {Kees van Deemter},\n",
      " journal = {Computational Linguistics},\n",
      " notes = {Empty},\n",
      " number = {2},\n",
      " pages = {195--222},\n",
      " title = {Generating referring expressions that involve gradable properties},\n",
      " url = {#},\n",
      " volume = {32},\n",
      " year = {2006}\n",
      "}\n",
      "\n",
      "@article{vilnis2014word,\n",
      " abstract = {Empty},\n",
      " author = {Vilnis, Luke and McCallum, Andrew},\n",
      " journal = {arXiv preprint arXiv:1412.6623},\n",
      " notes = {Empty},\n",
      " title = {Word representations via Gaussian embedding},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@inproceedings{vinyals2015show,\n",
      " abstract = {Empty},\n",
      " author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},\n",
      " booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n",
      " notes = {Empty},\n",
      " pages = {3156--3164},\n",
      " title = {Show and Tell: A Neural Image Caption Generator},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@article{Vogel2010,\n",
      " abstract = {We present a system that learns to fol- low navigational natural language direc- tions. Where traditional models learn from linguistic annotation or word distri- butions, our approach is grounded in the world, learning by apprenticeship from routes through a map paired with English descriptions. Lacking an explicit align- ment between the text and the reference path makes it difficult to determine what portions of the language describe which aspects of the route. We learn this corre- spondence with a reinforcement learning algorithm, using the deviation of the route we follow from the intended path as a re- ward signal. We demonstrate that our sys- tem successfully grounds the meaning of spatial terms like above and south into ge- ometric properties of paths.},\n",
      " annote = {alignment between RL space and map space. },\n",
      " author = {Vogel, Adam and Jurafsky, Dan},\n",
      " file = {:C$\\backslash$:/Users/brian_000/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vogel, Jurafsky - 2010 - Learning to Follow Navigational Directions(2).pdf:pdf},\n",
      " journal = {Computational Linguistics},\n",
      " notes = {Empty},\n",
      " pages = {806--814},\n",
      " title = {{Learning to Follow Navigational Directions}},\n",
      " url = {#},\n",
      " volume = {22},\n",
      " year = {2010}\n",
      "}\n",
      "\n",
      "@inproceedings{VonAhn2004,\n",
      " abstract = {We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.},\n",
      " author = {von Ahn, Luis and Dabbish, Laura},\n",
      " booktitle = {ACM Conference on Human Factors in Computing Systems},\n",
      " doi = {10.1145/985692.985733},\n",
      " isbn = {1581137028},\n",
      " issn = {00201669},\n",
      " keywords = {World Wide Web,distributed knowledge acquisition,image labeling,online games},\n",
      " mendeley-groups = {possqualsrefs},\n",
      " notes = {Empty},\n",
      " pages = {319 -- 326},\n",
      " pmid = {21701501},\n",
      " title = {{Labeling images with a computer game}},\n",
      " url = {#},\n",
      " year = {2004}\n",
      "}\n",
      "\n",
      "@phdthesis{vroman2014maximum,\n",
      " abstract = {Empty},\n",
      " author = {Vroman, Monica C},\n",
      " notes = {Empty},\n",
      " school = {Rutgers University-Graduate School-New Brunswick},\n",
      " title = {Maximum likelihood inverse reinforcement learning},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{wallsten1986measuring,\n",
      " abstract = {Empty},\n",
      " author = {Wallsten, Thomas S and Budescu, David V and Rapoport, Amnon and Zwick, Rami and Forsyth, Barbara},\n",
      " journal = {Journal of Experimental Psychology: General},\n",
      " notes = {Empty},\n",
      " number = {4},\n",
      " pages = {348},\n",
      " publisher = {American Psychological Association},\n",
      " title = {Measuring the vague meanings of probability terms.},\n",
      " url = {#},\n",
      " volume = {115},\n",
      " year = {1986}\n",
      "}\n",
      "\n",
      "@article{webster2012color,\n",
      " abstract = {Empty},\n",
      " author = {Webster, Michael A and Kay, Paul},\n",
      " journal = {Cognition},\n",
      " notes = {Empty},\n",
      " number = {3},\n",
      " pages = {375--392},\n",
      " publisher = {Elsevier},\n",
      " title = {Color categories and color appearance},\n",
      " url = {#},\n",
      " volume = {122},\n",
      " year = {2012}\n",
      "}\n",
      "\n",
      "@article{williams1992simple,\n",
      " abstract = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units.  These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed.  Specific expamples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right.  Also given are results that show how such algorithms can be naturally integrated with backpropagation.  We close with a brief discussion of a number of additional issues surrounded the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to develop similar but potentially more powerful reinforcement learning algorithms.},\n",
      " author = {Williams, Ronald J},\n",
      " journal = {Machine learning},\n",
      " notes = {Empty},\n",
      " number = {3-4},\n",
      " pages = {229--256},\n",
      " publisher = {Springer},\n",
      " title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},\n",
      " url = {#},\n",
      " volume = {8},\n",
      " year = {1992}\n",
      "}\n",
      "\n",
      "@book{williamson_t:1996a,\n",
      " abstract = {Empty},\n",
      " address = {London},\n",
      " author = {Timothy Williamson},\n",
      " notes = {Empty},\n",
      " publisher = {Routledge},\n",
      " title = {Vagueness},\n",
      " topic = {vagueness;},\n",
      " url = {#},\n",
      " xref = {Review: mcgee-mclaughlin_bp:1998a.},\n",
      " year = {1996}\n",
      "}\n",
      "\n",
      "@article{Winograd1971,\n",
      " abstract = {Empty},\n",
      " author = {Winograd, Terry},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/winograd_dissertation.pdf:pdf},\n",
      " mendeley-groups = {compling},\n",
      " notes = {Empty},\n",
      " title = {{Procedures as a representation for data in a computer program for understanding natural language}},\n",
      " url = {#},\n",
      " year = {1971}\n",
      "}\n",
      "\n",
      "@techreport{winograd1971feb,\n",
      " abstract = {Empty},\n",
      " author = {Winograd, Terry},\n",
      " institution = {Massachusetts Institute of Technology},\n",
      " notes = {Empty},\n",
      " number = {AI Technical Report 235},\n",
      " title = {Procedures as a Representation for Data in a Computer Program for Understanding Natural Language},\n",
      " url = {#},\n",
      " year = {1971}\n",
      "}\n",
      "\n",
      "@article{xu2015show,\n",
      " abstract = {Inspired by recent work in machine translation\n",
      "and object detection, we introduce an attention\n",
      "based model that automatically learns to describe\n",
      "the content of images. We describe how we\n",
      "can train this model in a deterministic manner\n",
      "using standard backpropagation techniques and\n",
      "stochastically by maximizing a variational lower\n",
      "bound. We also show through visualization how\n",
      "the model is able to automatically learn to fix its\n",
      "gaze on salient objects while generating the corresponding\n",
      "words in the output sequence. We\n",
      "validate the use of attention with state-of-theart\n",
      "performance on three benchmark datasets:\n",
      "Flickr8k, Flickr30k and MS COCO.},\n",
      " author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},\n",
      " journal = {arXiv preprint arXiv:1502.03044},\n",
      " notes = {Empty},\n",
      " title = {Show, attend and tell: Neural image caption generation with visual attention},\n",
      " url = {#},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@article{yatskar2014see,\n",
      " abstract = {Empty},\n",
      " author = {Yatskar, Mark and Vanderwende, Lucy and Zettlemoyer, Luke},\n",
      " journal = {Lexical and Computational Semantics (* SEM 2014)},\n",
      " notes = {Empty},\n",
      " pages = {110},\n",
      " title = {See no evil, say no evil: Description generation from densely labeled images},\n",
      " url = {#},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{yendrik:color,\n",
      " abstract = {Empty},\n",
      " author = {Yendrikhovskij, S. N. and Blommaert, F. J. J. and de Ridder, H.},\n",
      " issn = {1520-6378},\n",
      " journal = {Color Research & Application},\n",
      " keywords = {color reproduction, naturalness, image processing},\n",
      " notes = {Empty},\n",
      " number = {1},\n",
      " pages = {52--67},\n",
      " publisher = {John Wiley & Sons, Inc.},\n",
      " title = {Color reproduction and the naturalness constraint},\n",
      " url = {#},\n",
      " volume = {24},\n",
      " year = {1999}\n",
      "}\n",
      "\n",
      "@article{Young2014,\n",
      " abstract = {Empty},\n",
      " author = {Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/young_etal_tacl_2014.pdf:pdf},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " mendeley-groups = {compling/grounded semantics,compling,quals},\n",
      " notes = {Empty},\n",
      " pages = {67--78},\n",
      " title = {{From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions}},\n",
      " url = {#},\n",
      " volume = {2},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{young2014image,\n",
      " abstract = {Empty},\n",
      " author = {Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},\n",
      " journal = {Transactions of the Association for Computational Linguistics},\n",
      " notes = {Empty},\n",
      " pages = {67--78},\n",
      " title = {From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},\n",
      " url = {#},\n",
      " volume = {2},\n",
      " year = {2014}\n",
      "}\n",
      "\n",
      "@article{yu/ballard:tap04,\n",
      " abstract = {Empty},\n",
      " author = {Chen Yu and Dana H. Ballard},\n",
      " journal = {{ACM} Transactions on Applied Perception},\n",
      " notes = {Empty},\n",
      " pages = {57--80},\n",
      " title = {A multimodal learning interface for grounding spoken language in sensory perceptions},\n",
      " url = {#},\n",
      " volume = {1},\n",
      " year = {2004}\n",
      "}\n",
      "\n",
      "@inproceedings{zarriess2016towards,\n",
      " abstract = {Colour terms have been a prime phenomenon for studying language grounding, though previous\n",
      "work focussed mostly on descriptions of simple objects or colour swatches. This\n",
      "paper investigates whether colour terms can be learned from more realistic and potentially\n",
      "noisy visual inputs, using a corpus of referring expressions to objects represented as regions\n",
      "in real-world images. We obtain promising results from combining a classifier that grounds\n",
      "colour terms in visual input with a recalibration model that adjusts probability distributions\n",
      "over colour terms according to contextual and object-specific preferences.},\n",
      " author = {Zarrieß, Sina and Schlangen, David},\n",
      " booktitle = {Proceedings of the 9th International Natural Language Generation conference},\n",
      " notes = {Empty},\n",
      " title = {Towards Generating Colour Terms for Referents in Photographs: Prefer the Expected or the Unexpected?},\n",
      " url = {https://pub.uni-bielefeld.de/download/2905650/2905652},\n",
      " year = {2016}\n",
      "}\n",
      "\n",
      "@article{Zelle1996,\n",
      " abstract = {Empty},\n",
      " author = {Zelle, John M and Mooney, Raymond J},\n",
      " booktitle = {Proceedings of the National Conference on Artificial Intelligence},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/parsing/ilp_zelle_mooney_1996.pdf:pdf},\n",
      " mendeley-groups = {compling,tutorials},\n",
      " notes = {Empty},\n",
      " number = {August},\n",
      " pages = {1050--1055},\n",
      " title = {Learning to parse database queries using inductive logic programming},\n",
      " url = {#},\n",
      " year = {1996}\n",
      "}\n",
      "\n",
      "@article{Zelle1997,\n",
      " abstract = {Empty},\n",
      " author = {Zelle, JM and Mooney, RJ},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/inductive logic programming/zelle_mooney_chill_1997.pdf:pdf},\n",
      " journal = {Unpublished Technical Report},\n",
      " mendeley-groups = {compling},\n",
      " notes = {Empty},\n",
      " pages = {1--58},\n",
      " title = {{An inductive logic programming method for corpus-based parser construction}},\n",
      " url = {#},\n",
      " year = {1997}\n",
      "}\n",
      "\n",
      "@inproceedings{Zettlemoyer2005,\n",
      " abstract = {Empty},\n",
      " author = {Zettlemoyer, LS and Collins, Michael},\n",
      " booktitle = {Proceedings of the Twenty First Conference on Uncertainty in Artificial Intelligence (UAI)},\n",
      " file = {:C$\\backslash$:/research/papers/computational linguistics/grounded semantics/zottlemoyer_mapping_lf.pdf:pdf},\n",
      " mendeley-groups = {compling},\n",
      " notes = {Empty},\n",
      " title = {{Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars}},\n",
      " url = {#},\n",
      " year = {2005}\n",
      "}\n",
      "\n",
      "@inproceedings{ZettlemoyerC05,\n",
      " abstract = {Empty},\n",
      " author = {Luke S. Zettlemoyer and\n",
      "Michael Collins},\n",
      " booktitle = {UAI '05, Proceedings of the 21st Conference in Uncertainty\n",
      "in Artificial Intelligence},\n",
      " notes = {Empty},\n",
      " pages = {658--666},\n",
      " title = {Learning to Map Sentences to Logical Form: Structured Classification\n",
      "with Probabilistic Categorial Grammars},\n",
      " url = {#},\n",
      " year = {2005}\n",
      "}\n",
      "\n",
      "@article{ZhangLL15,\n",
      " abstract = {Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have been successfully applied to a variety of sequence modeling tasks. In this paper we develop Tree Long Short-Term Memory (TreeLSTM), a neural network model based on LSTM, which is designed to predict a tree rather than a linear sequence. TreeLSTM defines the probability of a sentence by estimating the generation probability of its dependency tree. At each time step, a node is generated based on the representation of the generated sub-tree. We further enhance the modeling power of TreeLSTM by explicitly representing the correlations between left and right dependents. Application of our model to the MSR sentence completion challenge achieves results beyond the current state of the art. We also report results on dependency parsing reranking achieving competitive performance.},\n",
      " author = {Xingxing Zhang and\n",
      "Liang Lu and\n",
      "Mirella Lapata},\n",
      " bibsource = {dblp computer science bibliography, http://dblp.org},\n",
      " biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/ZhangLL15},\n",
      " journal = {CoRR},\n",
      " notes = {Empty},\n",
      " timestamp = {Tue, 01 Dec 2015 19:22:34 +0100},\n",
      " title = {Tree Recurrent Neural Networks with Application to Language Modeling},\n",
      " url = {#},\n",
      " volume = {abs/1511.00060},\n",
      " year = {2015}\n",
      "}\n",
      "\n",
      "@inproceedings{ziebart2008maximum,\n",
      " abstract = {Empty},\n",
      " author = {Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},\n",
      " bib = {Recent research has shown the benefit of framing problems\n",
      "of imitation learning as solutions to Markov Decision Problems.\n",
      "This approach reduces learning to the problem of recovering\n",
      "a utility function that makes the behavior induced\n",
      "by a near-optimal policy closely mimic demonstrated behavior.\n",
      "In this work, we develop a probabilistic approach based\n",
      "on the principle of maximum entropy. Our approach provides\n",
      "a well-defined, globally normalized distribution over decision\n",
      "sequences, while providing the same performance guarantees\n",
      "as existing methods.\n",
      "We develop our technique in the context of modeling realworld\n",
      "navigation and driving behaviors where collected data\n",
      "is inherently noisy and imperfect. Our probabilistic approach\n",
      "enables modeling of route preferences as well as a powerful\n",
      "new approach to inferring destinations and routes based on\n",
      "partial trajectories.},\n",
      " booktitle = {AAAI},\n",
      " notes = {Empty},\n",
      " pages = {1433--1438},\n",
      " title = {Maximum Entropy Inverse Reinforcement Learning.},\n",
      " url = {#},\n",
      " year = {2008}\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pybib.dumps(db2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BibEntry' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b2eef377ddb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entries_to_bibtex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/bcmcmahan/research/code/pybibtex/pybib/bwriter.pyc\u001b[0m in \u001b[0;36m_entries_to_bibtex\u001b[0;34m(self, bib_database)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_entries_by\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# TODO: allow sort field does not exist for entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbib_database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBibDatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_sort_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_entries_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbib_database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bcmcmahan/research/code/pybibtex/pybib/bwriter.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_entries_by\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# TODO: allow sort field does not exist for entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbib_database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBibDatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_sort_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_entries_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbib_database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bcmcmahan/research/code/pybibtex/pybib/bibdatabase.pyc\u001b[0m in \u001b[0;36mentry_sort_key\u001b[0;34m(entry, fields)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT_TYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sorting always as string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BibEntry' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "len(bw._entries_to_bibtex(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([inproceedings][jager:ac09], {u'pages': [2, 3]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixes['jager:ac09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
